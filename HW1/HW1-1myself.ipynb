{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = 10\n",
    "\n",
    "test = np.load('test.npz')\n",
    "train = np.load('train.npz')\n",
    "\n",
    "y_test = test['label']\n",
    "x_test = test['image']\n",
    "y_train = train['label']\n",
    "x_train = train['image']\n",
    "\n",
    "x_train = x_train.reshape(-1, x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(-1, x_test.shape[1] * x_test.shape[2])\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "X = np.vstack((x_train, x_test))\n",
    "y = np.vstack((y_train, y_test))\n",
    "\n",
    "examples = y.shape[0]\n",
    "y = y.reshape(1, examples)\n",
    "Y_new = np.eye(digits)[y.astype('int32')]\n",
    "Y_new = Y_new.T.reshape(digits, examples)\n",
    "  #print(y)\n",
    "\n",
    "m = x_train.shape[0]\n",
    "X_train, X_test = X[:m].T, X[m:].T\n",
    "Y_train, Y_test = Y_new[:, :m], Y_new[:, m:]\n",
    "\n",
    "shuffle_index = np.random.permutation(m)\n",
    "X_train, Y_train = X_train[:, shuffle_index], Y_train[:, shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1. / (1. + np.exp(-z))\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "#     # To prevent from overflow\n",
    "#     z = np.clip(z, 1e-15, 1 - 1e-15)\n",
    "    s = sigmoid(z) * (1 - sigmoid(z))\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(Y, Y_hat):\n",
    "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
    "    m = Y.shape[1]\n",
    "    L = -(1./m) * L_sum\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_gradient(Y, Y_hat):\n",
    "    L = Y_hat - Y\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    s = np.exp(z) / np.sum(np.exp(z), axis=0)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(predicts, golds):\n",
    "    correct = 0\n",
    "    total = len(predicts)\n",
    "    assert len(predicts) == len(golds)\n",
    "    for predict, gold in zip(predicts, golds):\n",
    "        if predict == gold:\n",
    "            correct += 1\n",
    "    accurancy = correct / total\n",
    "    return accurancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_, output):\n",
    "        self.input = input_\n",
    "        self.output = output  # number of layer node\n",
    "        self.W = np.random.randn(self.output, self.input) * np.sqrt(1. / self.input)\n",
    "        self.b = np.zeros((self.output, 1)) * np.sqrt(1. / self.input)\n",
    "        \n",
    "    def forward(self, last_layer):\n",
    "        self.last_layer = last_layer\n",
    "        layer_output = np.matmul(self.W, self.last_layer) + self.b\n",
    "#         layer_output = sigmoid(layer_output_temp)\n",
    "        return layer_output\n",
    "    \n",
    "    def back_propagation(self, CE_gradientorgradient, m_batch, learning_rate):\n",
    "        W_temp = self.W\n",
    "        W_gradient = (1. / m_batch) * np.matmul(CE_gradientorgradient, self.last_layer.T)\n",
    "        b_gradient = (1. / m_batch) * np.sum(CE_gradientorgradient, axis=1, keepdims=True)\n",
    "        self.W_new = self.W - learning_rate * W_gradient\n",
    "        self.b_new = self.b - learning_rate * b_gradient\n",
    "        self.W = self.W_new\n",
    "        self.b = self.b_new\n",
    "        gradient_temp = np.matmul(W_temp.T, CE_gradientorgradient)\n",
    "        return gradient_temp\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddenlayer1 = Layer(784, 400)\n",
    "hiddenlayer2 = Layer(400, 400)\n",
    "outputlayer = Layer(400, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_train_epoch(X_train, Y_train, batch_size = 64, epoch = 10, learning_rate = 0.03):\n",
    "    for i in range(epoch):\n",
    "       \n",
    "        # shuffle training set\n",
    "        permutation = np.random.permutation(X_train.shape[1])\n",
    "        X_train_shuffled = X_train[:, permutation]\n",
    "        Y_train_shuffled = Y_train[:, permutation]\n",
    "    \n",
    "        batch_num = len(X_train) // batch_size\n",
    "        predicts = []\n",
    "        golds = []\n",
    "        predicts_test = []\n",
    "        golds_test = []\n",
    "        \n",
    "        for j in range(batch_num):\n",
    "            begin = j * batch_size\n",
    "            end = min(begin + batch_size, X_train.shape[1] - 1)\n",
    "            X = X_train[:, begin:end]\n",
    "            Y = Y_train[:, begin:end]\n",
    "            m_batch = end - begin\n",
    "            \n",
    "            output1_temp = hiddenlayer1.forward(X)\n",
    "            output1 = sigmoid(output1_temp)\n",
    "            output2_temp = hiddenlayer2.forward(output1)\n",
    "            output2 = sigmoid(output2_temp)\n",
    "            y_hat_temp = outputlayer.forward(output2)\n",
    "            y_hat = softmax(y_hat_temp)\n",
    "            #print(y_hat)\n",
    "            \n",
    "            predicts += np.argmax(y_hat, axis = 0).tolist()\n",
    "            golds += np.argmax(Y, axis = 0).tolist()\n",
    "            \n",
    "            \n",
    "            loss = cross_entropy(Y, y_hat)\n",
    "            gradient = cross_entropy_gradient(Y, y_hat)\n",
    "            \n",
    "            back_output1 = outputlayer.back_propagation(gradient, m_batch, learning_rate)\n",
    "            back_output2_temp = sigmoid_gradient(output2_temp) * back_output1\n",
    "            back_output2 = hiddenlayer2.back_propagation(back_output2_temp, m_batch, learning_rate)\n",
    "            back_output3_temp = sigmoid_gradient(output1_temp) * back_output2\n",
    "            back_output3 = hiddenlayer1.back_propagation(back_output3_temp, m_batch, learning_rate)\n",
    "            \n",
    "            #---------test data-----------\n",
    "            \n",
    "            \n",
    "            output1_temp = hiddenlayer1.forward(X_test)\n",
    "            output1 = sigmoid(output1_temp)\n",
    "            output2_temp = hiddenlayer2.forward(output1)\n",
    "            output2 = sigmoid(output2_temp)\n",
    "            y_hat_temp = outputlayer.forward(output2)\n",
    "            y_hat = softmax(y_hat_temp)\n",
    "#             print(y_hat.shape)\n",
    "            #print(y_hat)\n",
    "#             print(Y_test.shape)\n",
    "            predicts_test += np.argmax(y_hat, axis=0).tolist()\n",
    "            golds_test += np.argmax(Y_test, axis=0).tolist()\n",
    "            \n",
    "            \n",
    "            loss_test = cross_entropy(Y_test, y_hat)\n",
    "            \n",
    "        print('Epoch : ', i + 1, 'training_loss = ', loss, 'test_loss = ', loss_test, 'train_accur = ', evaluation(predicts, golds), 'test_accur = ', evaluation(predicts_test, golds_test))\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1 training_loss =  2.3157105331529597 test_loss =  2.2923375338066214 train_accur =  0.11848958333333333 test_accur =  0.13570561719833565\n",
      "Epoch :  2 training_loss =  2.246985622304252 test_loss =  2.246816531120839 train_accur =  0.22526041666666666 test_accur =  0.18660425335182618\n",
      "Epoch :  3 training_loss =  2.20975154126718 test_loss =  2.2223439869743635 train_accur =  0.23177083333333334 test_accur =  0.19913025889967637\n",
      "Epoch :  4 training_loss =  2.179867829612064 test_loss =  2.20036003543622 train_accur =  0.24479166666666666 test_accur =  0.21208969024503005\n",
      "Epoch :  5 training_loss =  2.1545609267310883 test_loss =  2.1776446236693245 train_accur =  0.265625 test_accur =  0.22659500693481277\n",
      "Epoch :  6 training_loss =  2.1288969656303323 test_loss =  2.155657838780315 train_accur =  0.29296875 test_accur =  0.24354195561719832\n",
      "Epoch :  7 training_loss =  2.104601244657802 test_loss =  2.1343042379132053 train_accur =  0.3229166666666667 test_accur =  0.2614279935275081\n",
      "Epoch :  8 training_loss =  2.079524118616355 test_loss =  2.1137264149080504 train_accur =  0.35546875 test_accur =  0.28101883957466484\n",
      "Epoch :  9 training_loss =  2.0525643900163457 test_loss =  2.092874440545634 train_accur =  0.3893229166666667 test_accur =  0.30078305594082294\n",
      "Epoch :  10 training_loss =  2.0286415163020592 test_loss =  2.0728741309961225 train_accur =  0.4270833333333333 test_accur =  0.3215297041146556\n",
      "Epoch :  11 training_loss =  2.0052955064073856 test_loss =  2.0531911334062958 train_accur =  0.4466145833333333 test_accur =  0.34249306518723993\n",
      "Epoch :  12 training_loss =  1.9826538211326583 test_loss =  2.033727241884492 train_accur =  0.4635416666666667 test_accur =  0.36404877484974574\n",
      "Epoch :  13 training_loss =  1.9607636210273127 test_loss =  2.014591652130995 train_accur =  0.4934895833333333 test_accur =  0.38361072584373557\n",
      "Epoch :  14 training_loss =  1.936950188834512 test_loss =  1.9952503946869908 train_accur =  0.5104166666666666 test_accur =  0.40094775774387426\n",
      "Epoch :  15 training_loss =  1.9160696338966137 test_loss =  1.9758880605957623 train_accur =  0.53125 test_accur =  0.41887713823393435\n",
      "Epoch :  16 training_loss =  1.8949519064422007 test_loss =  1.9563377134650421 train_accur =  0.5520833333333334 test_accur =  0.43697988904299584\n",
      "Epoch :  17 training_loss =  1.8718821579879332 test_loss =  1.9364249142135666 train_accur =  0.5690104166666666 test_accur =  0.45307443365695793\n",
      "Epoch :  18 training_loss =  1.8478921108101374 test_loss =  1.9164301075451649 train_accur =  0.5859375 test_accur =  0.47085933888118353\n",
      "Epoch :  19 training_loss =  1.8256404938780013 test_loss =  1.8960755042511948 train_accur =  0.6002604166666666 test_accur =  0.48782073509015256\n",
      "Epoch :  20 training_loss =  1.8017757365302063 test_loss =  1.8760978918856872 train_accur =  0.6106770833333334 test_accur =  0.5027450300508552\n",
      "Epoch :  21 training_loss =  1.7778260834700288 test_loss =  1.8557946039786797 train_accur =  0.62890625 test_accur =  0.5167591308368007\n",
      "Epoch :  22 training_loss =  1.7544682530631237 test_loss =  1.8352974762526852 train_accur =  0.64453125 test_accur =  0.5302964632454924\n",
      "Epoch :  23 training_loss =  1.7292830525079292 test_loss =  1.8151698851729623 train_accur =  0.6653645833333334 test_accur =  0.5427646786870088\n",
      "Epoch :  24 training_loss =  1.7050156751289482 test_loss =  1.7948294552084247 train_accur =  0.6744791666666666 test_accur =  0.5543660425335183\n",
      "Epoch :  25 training_loss =  1.6816772663099293 test_loss =  1.7745929331666688 train_accur =  0.6861979166666666 test_accur =  0.5659674063800277\n",
      "Epoch :  26 training_loss =  1.6583447619073268 test_loss =  1.7544325672405914 train_accur =  0.6979166666666666 test_accur =  0.576788603791031\n",
      "Epoch :  27 training_loss =  1.6332141605321002 test_loss =  1.7343754358561585 train_accur =  0.71484375 test_accur =  0.5866418169209431\n",
      "Epoch :  28 training_loss =  1.610834006672562 test_loss =  1.7146581577274784 train_accur =  0.7200520833333334 test_accur =  0.5969717984281091\n",
      "Epoch :  29 training_loss =  1.589304657704452 test_loss =  1.6950493849238653 train_accur =  0.7265625 test_accur =  0.6062326629680999\n",
      "Epoch :  30 training_loss =  1.5657963550130773 test_loss =  1.6755961025260078 train_accur =  0.7330729166666666 test_accur =  0.6153634997688395\n",
      "Epoch :  31 training_loss =  1.542716132398013 test_loss =  1.6555430009884338 train_accur =  0.7408854166666666 test_accur =  0.6237719602404068\n",
      "Epoch :  32 training_loss =  1.519822989129047 test_loss =  1.6360253954719217 train_accur =  0.7565104166666666 test_accur =  0.6322815533980582\n",
      "Epoch :  33 training_loss =  1.497583811971996 test_loss =  1.6165939421716724 train_accur =  0.7630208333333334 test_accur =  0.639288603791031\n",
      "Epoch :  34 training_loss =  1.4758545274704262 test_loss =  1.597120864312002 train_accur =  0.76953125 test_accur =  0.6473503236245954\n",
      "Epoch :  35 training_loss =  1.452701186371851 test_loss =  1.5780019257514986 train_accur =  0.7721354166666666 test_accur =  0.6542128987517337\n",
      "Epoch :  36 training_loss =  1.4302912971977713 test_loss =  1.5587528112721474 train_accur =  0.78515625 test_accur =  0.6610899214054554\n",
      "Epoch :  37 training_loss =  1.4075268804095356 test_loss =  1.5396872780483106 train_accur =  0.7916666666666666 test_accur =  0.6679524965325936\n",
      "Epoch :  38 training_loss =  1.3859692750257113 test_loss =  1.520978597638619 train_accur =  0.7955729166666666 test_accur =  0.6738326398520573\n",
      "Epoch :  39 training_loss =  1.3641678570831959 test_loss =  1.502746997119247 train_accur =  0.8098958333333334 test_accur =  0.6795249653259362\n",
      "Epoch :  40 training_loss =  1.3442720710226348 test_loss =  1.4849676808714076 train_accur =  0.8151041666666666 test_accur =  0.6835847202958854\n",
      "Epoch :  41 training_loss =  1.3218671567587186 test_loss =  1.4672268567321554 train_accur =  0.8255208333333334 test_accur =  0.6872832871012483\n",
      "Epoch :  42 training_loss =  1.300052433295722 test_loss =  1.4499558136385633 train_accur =  0.83203125 test_accur =  0.6918631530282016\n",
      "Epoch :  43 training_loss =  1.2790007557513343 test_loss =  1.4327785318926143 train_accur =  0.8333333333333334 test_accur =  0.6947960009246417\n",
      "Epoch :  44 training_loss =  1.258895223087141 test_loss =  1.4158534924014652 train_accur =  0.8411458333333334 test_accur =  0.6984367776236708\n",
      "Epoch :  45 training_loss =  1.239926825388603 test_loss =  1.399167944712592 train_accur =  0.84375 test_accur =  0.7020197642163661\n",
      "Epoch :  46 training_loss =  1.2223700760827614 test_loss =  1.3826304609218205 train_accur =  0.8463541666666666 test_accur =  0.7059350439204808\n",
      "Epoch :  47 training_loss =  1.2033868108133252 test_loss =  1.3660423594383195 train_accur =  0.8463541666666666 test_accur =  0.7094457928802589\n",
      "Epoch :  48 training_loss =  1.1852587494425804 test_loss =  1.350179733416177 train_accur =  0.84765625 test_accur =  0.7127976190476191\n",
      "Epoch :  49 training_loss =  1.1677536057011182 test_loss =  1.3346420052346342 train_accur =  0.8515625 test_accur =  0.7158460471567267\n",
      "Epoch :  50 training_loss =  1.149715099068442 test_loss =  1.3185388485751708 train_accur =  0.8567708333333334 test_accur =  0.7199346971798428\n",
      "Epoch :  51 training_loss =  1.1313515058111467 test_loss =  1.3031277158328722 train_accur =  0.8580729166666666 test_accur =  0.7235754738788719\n",
      "Epoch :  52 training_loss =  1.1136831301430925 test_loss =  1.2881931858376108 train_accur =  0.859375 test_accur =  0.7261615811373093\n",
      "Epoch :  53 training_loss =  1.0965896181849957 test_loss =  1.274003275073018 train_accur =  0.8658854166666666 test_accur =  0.7286032131299122\n",
      "Epoch :  54 training_loss =  1.0801975280573433 test_loss =  1.259786592422996 train_accur =  0.8658854166666666 test_accur =  0.7312326629680999\n",
      "Epoch :  55 training_loss =  1.0643416709652842 test_loss =  1.2455119855522672 train_accur =  0.87109375 test_accur =  0.7347000693481276\n",
      "Epoch :  56 training_loss =  1.0483326081745596 test_loss =  1.2319104380125008 train_accur =  0.875 test_accur =  0.7367227230698105\n",
      "Epoch :  57 training_loss =  1.0320154885682995 test_loss =  1.218405192797488 train_accur =  0.8763020833333334 test_accur =  0.7391354600092465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  58 training_loss =  1.0167767020800276 test_loss =  1.2048859741142548 train_accur =  0.875 test_accur =  0.7413603791030976\n",
      "Epoch :  59 training_loss =  1.0011870888293823 test_loss =  1.192068212749601 train_accur =  0.8802083333333334 test_accur =  0.7438886962552012\n",
      "Epoch :  60 training_loss =  0.9858799673348386 test_loss =  1.1790851329976746 train_accur =  0.8815104166666666 test_accur =  0.7459691400832178\n",
      "Epoch :  61 training_loss =  0.9714486670079439 test_loss =  1.166901486403053 train_accur =  0.8828125 test_accur =  0.748136269070735\n",
      "Epoch :  62 training_loss =  0.9573588904149427 test_loss =  1.1547232206957727 train_accur =  0.8880208333333334 test_accur =  0.7499855524734166\n",
      "Epoch :  63 training_loss =  0.9446966980492532 test_loss =  1.1429974488728567 train_accur =  0.8893229166666666 test_accur =  0.7517770457697642\n",
      "Epoch :  64 training_loss =  0.9308842279483178 test_loss =  1.1311852577394383 train_accur =  0.890625 test_accur =  0.7538141470180305\n",
      "Epoch :  65 training_loss =  0.9171699031473629 test_loss =  1.1200531497467403 train_accur =  0.8932291666666666 test_accur =  0.75582235321313\n",
      "Epoch :  66 training_loss =  0.9048152247836173 test_loss =  1.1089569934172867 train_accur =  0.8919270833333334 test_accur =  0.7574838187702265\n",
      "Epoch :  67 training_loss =  0.8923123148919349 test_loss =  1.0981180825987418 train_accur =  0.8932291666666666 test_accur =  0.7588707813222376\n",
      "Epoch :  68 training_loss =  0.8798301812392608 test_loss =  1.08761521709554 train_accur =  0.89453125 test_accur =  0.761037910309755\n",
      "Epoch :  69 training_loss =  0.8684534630275036 test_loss =  1.077214334423246 train_accur =  0.89453125 test_accur =  0.7629449838187702\n",
      "Epoch :  70 training_loss =  0.8556998072283498 test_loss =  1.0671923838675548 train_accur =  0.8971354166666666 test_accur =  0.764707582061951\n",
      "Epoch :  71 training_loss =  0.8435223749694573 test_loss =  1.05705596178834 train_accur =  0.8984375 test_accur =  0.7660945446139621\n",
      "Epoch :  72 training_loss =  0.8316465395263002 test_loss =  1.047302038990759 train_accur =  0.9010416666666666 test_accur =  0.7674815071659732\n",
      "Epoch :  73 training_loss =  0.8200336900427516 test_loss =  1.037991770038284 train_accur =  0.90234375 test_accur =  0.768666204345816\n",
      "Epoch :  74 training_loss =  0.8089099246528515 test_loss =  1.0285621046962725 train_accur =  0.90234375 test_accur =  0.7695619509939898\n",
      "Epoch :  75 training_loss =  0.7980678592050108 test_loss =  1.019314982757371 train_accur =  0.90625 test_accur =  0.7707033055940823\n",
      "Epoch :  76 training_loss =  0.7866877000961107 test_loss =  1.010487181234476 train_accur =  0.90625 test_accur =  0.7721336107258437\n",
      "Epoch :  77 training_loss =  0.7760156024160079 test_loss =  1.0015228342420013 train_accur =  0.9075520833333334 test_accur =  0.7729571197411004\n",
      "Epoch :  78 training_loss =  0.7653094406366674 test_loss =  0.9929006542215345 train_accur =  0.9075520833333334 test_accur =  0.7736506010171059\n",
      "Epoch :  79 training_loss =  0.7554971147745162 test_loss =  0.9847331463282337 train_accur =  0.9088541666666666 test_accur =  0.7746330328247804\n",
      "Epoch :  80 training_loss =  0.7463867008651912 test_loss =  0.976547155444751 train_accur =  0.9088541666666666 test_accur =  0.7756732547387887\n",
      "Epoch :  81 training_loss =  0.737115045052754 test_loss =  0.9685940144054845 train_accur =  0.9088541666666666 test_accur =  0.7764967637540453\n",
      "Epoch :  82 training_loss =  0.7282098811345059 test_loss =  0.9608465557691298 train_accur =  0.9114583333333334 test_accur =  0.7770457697642164\n",
      "Epoch :  83 training_loss =  0.71907596880075 test_loss =  0.9532085401441415 train_accur =  0.9114583333333334 test_accur =  0.777580328247804\n",
      "Epoch :  84 training_loss =  0.7101369179741697 test_loss =  0.9454760518079365 train_accur =  0.9114583333333334 test_accur =  0.7782015718908922\n",
      "Epoch :  85 training_loss =  0.7008541750331467 test_loss =  0.9381093769513822 train_accur =  0.9114583333333334 test_accur =  0.7791984512251503\n",
      "Epoch :  86 training_loss =  0.6925771703143453 test_loss =  0.9309709199149135 train_accur =  0.91015625 test_accur =  0.7801953305594083\n",
      "Epoch :  87 training_loss =  0.6836327217563571 test_loss =  0.9238875567838907 train_accur =  0.9140625 test_accur =  0.780542071197411\n",
      "Epoch :  88 training_loss =  0.6748775173929756 test_loss =  0.9169518645110517 train_accur =  0.9140625 test_accur =  0.7815245030050856\n",
      "Epoch :  89 training_loss =  0.6667196576638692 test_loss =  0.9102676424784217 train_accur =  0.9140625 test_accur =  0.7821746417013408\n",
      "Epoch :  90 training_loss =  0.6589549963337837 test_loss =  0.903700863428416 train_accur =  0.9166666666666666 test_accur =  0.7827236477115118\n",
      "Epoch :  91 training_loss =  0.6514321099551794 test_loss =  0.8972873488066251 train_accur =  0.9166666666666666 test_accur =  0.7833448913546001\n",
      "Epoch :  92 training_loss =  0.6442090605132076 test_loss =  0.891195066577938 train_accur =  0.9166666666666666 test_accur =  0.7840383726306056\n",
      "Epoch :  93 training_loss =  0.6371876482483658 test_loss =  0.8850282507215038 train_accur =  0.9166666666666666 test_accur =  0.7847896440129449\n",
      "Epoch :  94 training_loss =  0.629873556410285 test_loss =  0.8789677038915402 train_accur =  0.9153645833333334 test_accur =  0.7854397827092002\n",
      "Epoch :  95 training_loss =  0.6234852526505943 test_loss =  0.8730918539080023 train_accur =  0.91796875 test_accur =  0.7861621590383726\n",
      "Epoch :  96 training_loss =  0.6161390994967225 test_loss =  0.867415359266169 train_accur =  0.91796875 test_accur =  0.7868989828941285\n",
      "Epoch :  97 training_loss =  0.6091053877140935 test_loss =  0.8620011351095103 train_accur =  0.91796875 test_accur =  0.7873613037447988\n",
      "Epoch :  98 training_loss =  0.6026988876393073 test_loss =  0.8564785820897536 train_accur =  0.9192708333333334 test_accur =  0.7881125751271383\n",
      "Epoch :  99 training_loss =  0.5963615950729925 test_loss =  0.8510081238317064 train_accur =  0.9192708333333334 test_accur =  0.7886760286638927\n",
      "Epoch :  100 training_loss =  0.5897740967579872 test_loss =  0.8457521261778573 train_accur =  0.9192708333333334 test_accur =  0.7893839574664817\n",
      "Epoch :  101 training_loss =  0.5838008931385159 test_loss =  0.8405164520250245 train_accur =  0.921875 test_accur =  0.7900774387424873\n",
      "Epoch :  102 training_loss =  0.5774021521607413 test_loss =  0.8352003985529098 train_accur =  0.9244791666666666 test_accur =  0.7909009477577439\n",
      "Epoch :  103 training_loss =  0.5702002165852806 test_loss =  0.8302070387835166 train_accur =  0.92578125 test_accur =  0.791421058714748\n",
      "Epoch :  104 training_loss =  0.5636374337550343 test_loss =  0.8253182643749679 train_accur =  0.9270833333333334 test_accur =  0.7920856449375867\n",
      "Epoch :  105 training_loss =  0.5574863799081835 test_loss =  0.8204654276405811 train_accur =  0.9270833333333334 test_accur =  0.7931114193250116\n",
      "Epoch :  106 training_loss =  0.5512379418337819 test_loss =  0.8156014734879723 train_accur =  0.9283854166666666 test_accur =  0.7936893203883495\n",
      "Epoch :  107 training_loss =  0.5447106857215716 test_loss =  0.8110387479882991 train_accur =  0.9283854166666666 test_accur =  0.7942094313453537\n",
      "Epoch :  108 training_loss =  0.538574336761219 test_loss =  0.8064203082333924 train_accur =  0.9296875 test_accur =  0.7948595700416089\n",
      "Epoch :  109 training_loss =  0.5332033162284642 test_loss =  0.8018706047441195 train_accur =  0.9296875 test_accur =  0.7960009246417014\n",
      "Epoch :  110 training_loss =  0.5278670542224515 test_loss =  0.797468423887403 train_accur =  0.9296875 test_accur =  0.7969400138696255\n",
      "Epoch :  111 training_loss =  0.5227549436986046 test_loss =  0.7933017078869141 train_accur =  0.9296875 test_accur =  0.7979513407304669\n",
      "Epoch :  112 training_loss =  0.5176185546046814 test_loss =  0.7890795654133089 train_accur =  0.9296875 test_accur =  0.7984858992140546\n",
      "Epoch :  113 training_loss =  0.5123364331716758 test_loss =  0.7848292687330697 train_accur =  0.9296875 test_accur =  0.7990638002773925\n",
      "Epoch :  114 training_loss =  0.5071027413813409 test_loss =  0.7806788833598217 train_accur =  0.9296875 test_accur =  0.7994972260748959\n",
      "Epoch :  115 training_loss =  0.5018373534479195 test_loss =  0.7767436232515792 train_accur =  0.9296875 test_accur =  0.7996705963938974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  116 training_loss =  0.49687370389564267 test_loss =  0.7729182380742229 train_accur =  0.9283854166666666 test_accur =  0.8004652103559871\n",
      "Epoch :  117 training_loss =  0.49198859690804164 test_loss =  0.7691338873295916 train_accur =  0.9283854166666666 test_accur =  0.8006674757281553\n",
      "Epoch :  118 training_loss =  0.4869838388564155 test_loss =  0.7654407874091701 train_accur =  0.9283854166666666 test_accur =  0.8011875866851595\n",
      "Epoch :  119 training_loss =  0.48186028076980647 test_loss =  0.7618471808198817 train_accur =  0.9296875 test_accur =  0.801490984743412\n",
      "Epoch :  120 training_loss =  0.47729734764152576 test_loss =  0.758347622803246 train_accur =  0.9296875 test_accur =  0.8020255432269995\n",
      "Epoch :  121 training_loss =  0.47250272835760987 test_loss =  0.7548618742452348 train_accur =  0.93359375 test_accur =  0.8028346047156727\n",
      "Epoch :  122 training_loss =  0.4681136178741182 test_loss =  0.7513921725695862 train_accur =  0.9348958333333334 test_accur =  0.803036870087841\n",
      "Epoch :  123 training_loss =  0.46347695176416365 test_loss =  0.7479773678653374 train_accur =  0.9348958333333334 test_accur =  0.8032824780397596\n",
      "Epoch :  124 training_loss =  0.45889436643864556 test_loss =  0.7449774359354647 train_accur =  0.9361979166666666 test_accur =  0.8035280859916782\n",
      "Epoch :  125 training_loss =  0.45432804326412884 test_loss =  0.7415958176167686 train_accur =  0.9361979166666666 test_accur =  0.8036725612575127\n",
      "Epoch :  126 training_loss =  0.44973170863225737 test_loss =  0.7380969233755803 train_accur =  0.9361979166666666 test_accur =  0.8044960702727693\n",
      "Epoch :  127 training_loss =  0.4456408949843742 test_loss =  0.7349310864566687 train_accur =  0.9361979166666666 test_accur =  0.8047705732778548\n",
      "Epoch :  128 training_loss =  0.44341543591099813 test_loss =  0.7316692330483089 train_accur =  0.9361979166666666 test_accur =  0.8058974803513639\n",
      "Epoch :  129 training_loss =  0.43835264309912253 test_loss =  0.728625343030377 train_accur =  0.9375 test_accur =  0.8061430883032825\n",
      "Epoch :  130 training_loss =  0.4341220754357435 test_loss =  0.7256457447292926 train_accur =  0.9375 test_accur =  0.8059552704576977\n",
      "Epoch :  131 training_loss =  0.4303400479266888 test_loss =  0.7226617012465748 train_accur =  0.9375 test_accur =  0.8065187239944521\n",
      "Epoch :  132 training_loss =  0.42670152033557596 test_loss =  0.7198149188976921 train_accur =  0.9375 test_accur =  0.8065765141007859\n",
      "Epoch :  133 training_loss =  0.4232641308605208 test_loss =  0.7168982717643199 train_accur =  0.9388020833333334 test_accur =  0.8066198566805363\n",
      "Epoch :  134 training_loss =  0.4197348309521596 test_loss =  0.713946625287427 train_accur =  0.9388020833333334 test_accur =  0.8068654646324549\n",
      "Epoch :  135 training_loss =  0.41639846291293614 test_loss =  0.7111350038852693 train_accur =  0.9401041666666666 test_accur =  0.8070677300046232\n",
      "Epoch :  136 training_loss =  0.41287968632158806 test_loss =  0.7083596605431582 train_accur =  0.9401041666666666 test_accur =  0.8074000231160425\n",
      "Epoch :  137 training_loss =  0.40950365853395254 test_loss =  0.7056638777959667 train_accur =  0.9401041666666666 test_accur =  0.8077323162274619\n",
      "Epoch :  138 training_loss =  0.405892008945935 test_loss =  0.7030180944411228 train_accur =  0.9401041666666666 test_accur =  0.8078912390198798\n",
      "Epoch :  139 training_loss =  0.4024258367479251 test_loss =  0.7004452123950721 train_accur =  0.94140625 test_accur =  0.8083246648173833\n",
      "Epoch :  140 training_loss =  0.39900162749445306 test_loss =  0.6978883517937046 train_accur =  0.94140625 test_accur =  0.8086425104022191\n",
      "Epoch :  141 training_loss =  0.3958523697818729 test_loss =  0.6953509565306604 train_accur =  0.94140625 test_accur =  0.8087580906148867\n",
      "Epoch :  142 training_loss =  0.3923235120025439 test_loss =  0.6928192691683173 train_accur =  0.94140625 test_accur =  0.8090614886731392\n",
      "Epoch :  143 training_loss =  0.38886014179848505 test_loss =  0.6903655392814501 train_accur =  0.94140625 test_accur =  0.8094515718908922\n",
      "Epoch :  144 training_loss =  0.3857417231464667 test_loss =  0.6880218411927955 train_accur =  0.94140625 test_accur =  0.809798312528895\n",
      "Epoch :  145 training_loss =  0.3828369145267153 test_loss =  0.6856891029019208 train_accur =  0.94140625 test_accur =  0.8098994452149791\n",
      "Epoch :  146 training_loss =  0.3797855305190314 test_loss =  0.6833494645795222 train_accur =  0.94140625 test_accur =  0.8102172907998151\n",
      "Epoch :  147 training_loss =  0.37628843823679714 test_loss =  0.6810348822302746 train_accur =  0.94140625 test_accur =  0.8104051086453999\n",
      "Epoch :  148 training_loss =  0.3746148615298497 test_loss =  0.678857095750477 train_accur =  0.9427083333333334 test_accur =  0.8105206888580675\n",
      "Epoch :  149 training_loss =  0.37068217492203415 test_loss =  0.6764844111854503 train_accur =  0.9427083333333334 test_accur =  0.8107085067036524\n",
      "Epoch :  150 training_loss =  0.3678235925919073 test_loss =  0.6743183414564937 train_accur =  0.9427083333333334 test_accur =  0.811084142394822\n",
      "Epoch :  151 training_loss =  0.36517579029233693 test_loss =  0.672129785101551 train_accur =  0.9427083333333334 test_accur =  0.8111274849745723\n",
      "Epoch :  152 training_loss =  0.3622975113333947 test_loss =  0.6699798075180267 train_accur =  0.9427083333333334 test_accur =  0.8112719602404068\n",
      "Epoch :  153 training_loss =  0.35955767380832204 test_loss =  0.6678737983863426 train_accur =  0.9427083333333334 test_accur =  0.8114308830328247\n",
      "Epoch :  154 training_loss =  0.35693210768408995 test_loss =  0.6657775421559858 train_accur =  0.9427083333333334 test_accur =  0.8115175681923255\n",
      "Epoch :  155 training_loss =  0.3541809930013473 test_loss =  0.6637400576829909 train_accur =  0.9440104166666666 test_accur =  0.8117053860379103\n",
      "Epoch :  156 training_loss =  0.35115338548756764 test_loss =  0.6617325038010036 train_accur =  0.9440104166666666 test_accur =  0.8125433425797504\n",
      "Epoch :  157 training_loss =  0.34852227986782786 test_loss =  0.6596647853551793 train_accur =  0.9440104166666666 test_accur =  0.8124855524734166\n",
      "Epoch :  158 training_loss =  0.34541885170308506 test_loss =  0.6577634166543149 train_accur =  0.9453125 test_accur =  0.8125288950531669\n",
      "Epoch :  159 training_loss =  0.3427896955723264 test_loss =  0.6558479605044301 train_accur =  0.9453125 test_accur =  0.8127167128987517\n",
      "Epoch :  160 training_loss =  0.34004747992661255 test_loss =  0.6537743326553742 train_accur =  0.9466145833333334 test_accur =  0.8131501386962552\n",
      "Epoch :  161 training_loss =  0.33764079649699413 test_loss =  0.6519848455727182 train_accur =  0.9479166666666666 test_accur =  0.8133090614886731\n",
      "Epoch :  162 training_loss =  0.33473625706294236 test_loss =  0.6501589866865124 train_accur =  0.94921875 test_accur =  0.813496879334258\n",
      "Epoch :  163 training_loss =  0.33217337567814326 test_loss =  0.6483202793060563 train_accur =  0.94921875 test_accur =  0.8138869625520111\n",
      "Epoch :  164 training_loss =  0.3297600097521059 test_loss =  0.6465145647599374 train_accur =  0.94921875 test_accur =  0.814074780397596\n",
      "Epoch :  165 training_loss =  0.3273664986047282 test_loss =  0.6447579345910289 train_accur =  0.94921875 test_accur =  0.8145659963014332\n",
      "Epoch :  166 training_loss =  0.32498966612041325 test_loss =  0.6430980798763805 train_accur =  0.94921875 test_accur =  0.8147682616736015\n",
      "Epoch :  167 training_loss =  0.3226967244830656 test_loss =  0.6413447029958124 train_accur =  0.94921875 test_accur =  0.8148260517799353\n",
      "Epoch :  168 training_loss =  0.3204369399186665 test_loss =  0.6396406685236359 train_accur =  0.94921875 test_accur =  0.8149994220989366\n",
      "Epoch :  169 training_loss =  0.318228572151496 test_loss =  0.6380156350609665 train_accur =  0.94921875 test_accur =  0.8152305825242718\n",
      "Epoch :  170 training_loss =  0.3158654591260993 test_loss =  0.6364092603210578 train_accur =  0.94921875 test_accur =  0.815461742949607\n",
      "Epoch :  171 training_loss =  0.3137583608811609 test_loss =  0.6347572668749933 train_accur =  0.94921875 test_accur =  0.8157940360610264\n",
      "Epoch :  172 training_loss =  0.31153057037919146 test_loss =  0.6331820820265808 train_accur =  0.94921875 test_accur =  0.8160685390661119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  173 training_loss =  0.3095961371967615 test_loss =  0.6315941338538648 train_accur =  0.94921875 test_accur =  0.8160829865926953\n",
      "Epoch :  174 training_loss =  0.30755468427674737 test_loss =  0.6300653517624253 train_accur =  0.94921875 test_accur =  0.8162130143319464\n",
      "Epoch :  175 training_loss =  0.30534029635157095 test_loss =  0.62847761467616 train_accur =  0.94921875 test_accur =  0.8163719371243643\n",
      "Epoch :  176 training_loss =  0.3032824216231974 test_loss =  0.6270593202932431 train_accur =  0.94921875 test_accur =  0.8164008321775312\n",
      "Epoch :  177 training_loss =  0.30110016341478574 test_loss =  0.6255003748272393 train_accur =  0.94921875 test_accur =  0.8166030975496995\n",
      "Epoch :  178 training_loss =  0.29897786905907564 test_loss =  0.6240424105580296 train_accur =  0.94921875 test_accur =  0.8167042302357836\n",
      "Epoch :  179 training_loss =  0.29696131934379977 test_loss =  0.6226435116162009 train_accur =  0.94921875 test_accur =  0.8167909153952844\n",
      "Epoch :  180 training_loss =  0.29500135877307215 test_loss =  0.621187144805884 train_accur =  0.9505208333333334 test_accur =  0.8169787332408691\n",
      "Epoch :  181 training_loss =  0.2930646643566333 test_loss =  0.6197584567251694 train_accur =  0.9505208333333334 test_accur =  0.8171954461396209\n",
      "Epoch :  182 training_loss =  0.2910990228692695 test_loss =  0.6183716486065394 train_accur =  0.9505208333333334 test_accur =  0.8173688164586222\n",
      "Epoch :  183 training_loss =  0.289168338688138 test_loss =  0.6170251219314057 train_accur =  0.9505208333333334 test_accur =  0.817426606564956\n",
      "Epoch :  184 training_loss =  0.2872615327700888 test_loss =  0.6156244596449022 train_accur =  0.9505208333333334 test_accur =  0.8175277392510403\n",
      "Epoch :  185 training_loss =  0.2854182295689427 test_loss =  0.6142117047246647 train_accur =  0.9518229166666666 test_accur =  0.817744452149792\n",
      "Epoch :  186 training_loss =  0.28363582518506847 test_loss =  0.6128710180732512 train_accur =  0.9518229166666666 test_accur =  0.818033402681461\n",
      "Epoch :  187 training_loss =  0.28190132214699315 test_loss =  0.6115584935439645 train_accur =  0.9518229166666666 test_accur =  0.8182645631067961\n",
      "Epoch :  188 training_loss =  0.280194196078527 test_loss =  0.610285345540991 train_accur =  0.953125 test_accur =  0.8183512482662968\n",
      "Epoch :  189 training_loss =  0.27852100407127367 test_loss =  0.6089201646681467 train_accur =  0.953125 test_accur =  0.8186401987979658\n",
      "Epoch :  190 training_loss =  0.2769863682469583 test_loss =  0.6076195318025599 train_accur =  0.953125 test_accur =  0.8187557790106333\n",
      "Epoch :  191 training_loss =  0.2749046920874172 test_loss =  0.6064003560305704 train_accur =  0.953125 test_accur =  0.8188424641701341\n",
      "Epoch :  192 training_loss =  0.2728300135957853 test_loss =  0.6053045947539267 train_accur =  0.953125 test_accur =  0.8190158344891355\n",
      "Epoch :  193 training_loss =  0.2711075001705107 test_loss =  0.6040395305125822 train_accur =  0.953125 test_accur =  0.8191025196486361\n",
      "Epoch :  194 training_loss =  0.2693929156677467 test_loss =  0.6027393954039726 train_accur =  0.953125 test_accur =  0.8193192325473879\n",
      "Epoch :  195 training_loss =  0.26761189810040975 test_loss =  0.6014509359729179 train_accur =  0.953125 test_accur =  0.8194059177068885\n",
      "Epoch :  196 training_loss =  0.2660925747428746 test_loss =  0.600376168054686 train_accur =  0.953125 test_accur =  0.8197093157651411\n",
      "Epoch :  197 training_loss =  0.26443680149646226 test_loss =  0.5992089835350822 train_accur =  0.953125 test_accur =  0.8197093157651411\n",
      "Epoch :  198 training_loss =  0.2629868162732652 test_loss =  0.598031297452617 train_accur =  0.953125 test_accur =  0.819839343504392\n",
      "Epoch :  199 training_loss =  0.26170593665491526 test_loss =  0.596932204591827 train_accur =  0.953125 test_accur =  0.820128294036061\n",
      "Epoch :  200 training_loss =  0.2599587675477281 test_loss =  0.5956584955668653 train_accur =  0.9544270833333334 test_accur =  0.8203450069348127\n",
      "Epoch :  201 training_loss =  0.25848343193067025 test_loss =  0.5946147999229117 train_accur =  0.9544270833333334 test_accur =  0.8205328247803976\n",
      "Epoch :  202 training_loss =  0.2570487628472262 test_loss =  0.5935480155931148 train_accur =  0.9544270833333334 test_accur =  0.8207206426259824\n",
      "Epoch :  203 training_loss =  0.2556343274502705 test_loss =  0.5925082145145605 train_accur =  0.9544270833333334 test_accur =  0.8207350901525658\n",
      "Epoch :  204 training_loss =  0.25422929638963987 test_loss =  0.591475306493268 train_accur =  0.9557291666666666 test_accur =  0.820995145631068\n",
      "Epoch :  205 training_loss =  0.2529925685161046 test_loss =  0.5904388003387087 train_accur =  0.9557291666666666 test_accur =  0.8211829634766528\n",
      "Epoch :  206 training_loss =  0.251622016983324 test_loss =  0.5894687850690569 train_accur =  0.9557291666666666 test_accur =  0.8211540684234859\n",
      "Epoch :  207 training_loss =  0.2504408858942988 test_loss =  0.5883181263818283 train_accur =  0.9557291666666666 test_accur =  0.8211829634766528\n",
      "Epoch :  208 training_loss =  0.24874766902547635 test_loss =  0.5871863211408519 train_accur =  0.9557291666666666 test_accur =  0.8209084604715673\n",
      "Epoch :  209 training_loss =  0.24736094535521144 test_loss =  0.5862332536797287 train_accur =  0.9557291666666666 test_accur =  0.8212407535829865\n",
      "Epoch :  210 training_loss =  0.24592832597345107 test_loss =  0.585293084830108 train_accur =  0.9557291666666666 test_accur =  0.8212552011095701\n",
      "Epoch :  211 training_loss =  0.24442845849604036 test_loss =  0.5843674028044344 train_accur =  0.9557291666666666 test_accur =  0.8215730466944059\n",
      "Epoch :  212 training_loss =  0.24309344670192617 test_loss =  0.5833960828764382 train_accur =  0.9583333333333334 test_accur =  0.8217175219602404\n",
      "Epoch :  213 training_loss =  0.24172964780574063 test_loss =  0.5823899497388991 train_accur =  0.9583333333333334 test_accur =  0.8217608645399908\n",
      "Epoch :  214 training_loss =  0.24035059598854033 test_loss =  0.5814587729257205 train_accur =  0.9609375 test_accur =  0.8217897595931577\n",
      "Epoch :  215 training_loss =  0.23894487887547294 test_loss =  0.5804610082032418 train_accur =  0.9609375 test_accur =  0.8218764447526583\n",
      "Epoch :  216 training_loss =  0.2375344766748983 test_loss =  0.5794845709138979 train_accur =  0.9609375 test_accur =  0.8219053398058253\n",
      "Epoch :  217 training_loss =  0.23625047366468938 test_loss =  0.5785150877418028 train_accur =  0.9609375 test_accur =  0.8220353675450763\n",
      "Epoch :  218 training_loss =  0.23493916602831477 test_loss =  0.5775992449677781 train_accur =  0.9609375 test_accur =  0.8221365002311605\n",
      "Epoch :  219 training_loss =  0.23368136852245308 test_loss =  0.5766882156127934 train_accur =  0.9622395833333334 test_accur =  0.8221365002311605\n",
      "Epoch :  220 training_loss =  0.23245048334130447 test_loss =  0.5758288833659784 train_accur =  0.9622395833333334 test_accur =  0.8222809754969949\n",
      "Epoch :  221 training_loss =  0.2312482234512539 test_loss =  0.574898649455661 train_accur =  0.9622395833333334 test_accur =  0.8223098705501618\n",
      "Epoch :  222 training_loss =  0.22999023533494237 test_loss =  0.574103933549358 train_accur =  0.9622395833333334 test_accur =  0.8224110032362459\n",
      "Epoch :  223 training_loss =  0.22878711655177975 test_loss =  0.5733526120948549 train_accur =  0.9622395833333334 test_accur =  0.822541030975497\n",
      "Epoch :  224 training_loss =  0.2273915562356978 test_loss =  0.572335227262823 train_accur =  0.9622395833333334 test_accur =  0.8225988210818308\n",
      "Epoch :  225 training_loss =  0.2261095293072229 test_loss =  0.5714606339687471 train_accur =  0.9635416666666666 test_accur =  0.822541030975497\n",
      "Epoch :  226 training_loss =  0.2248245150405414 test_loss =  0.5706082446539051 train_accur =  0.9635416666666666 test_accur =  0.8224254507628294\n",
      "Epoch :  227 training_loss =  0.2233785391648656 test_loss =  0.569768221199681 train_accur =  0.9635416666666666 test_accur =  0.8227144012944984\n",
      "Epoch :  228 training_loss =  0.22212214797771548 test_loss =  0.5688429358546103 train_accur =  0.9635416666666666 test_accur =  0.8229311141932502\n",
      "Epoch :  229 training_loss =  0.2208858810046921 test_loss =  0.5680611720247141 train_accur =  0.9635416666666666 test_accur =  0.8228733240869163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  230 training_loss =  0.21975266119190692 test_loss =  0.5671788330099161 train_accur =  0.96484375 test_accur =  0.8229455617198336\n",
      "Epoch :  231 training_loss =  0.21857583200706215 test_loss =  0.5663766435943901 train_accur =  0.96484375 test_accur =  0.8229889042995839\n",
      "Epoch :  232 training_loss =  0.21742970983162102 test_loss =  0.5655820879284776 train_accur =  0.9661458333333334 test_accur =  0.8231622746185853\n",
      "Epoch :  233 training_loss =  0.21669540721907138 test_loss =  0.5647787039634442 train_accur =  0.9661458333333334 test_accur =  0.823220064724919\n",
      "Epoch :  234 training_loss =  0.21514490709581166 test_loss =  0.5640781712769928 train_accur =  0.9661458333333334 test_accur =  0.8234367776236708\n",
      "Epoch :  235 training_loss =  0.21391058577389155 test_loss =  0.5632852014678792 train_accur =  0.9661458333333334 test_accur =  0.823509015256588\n",
      "Epoch :  236 training_loss =  0.21283967682666008 test_loss =  0.5625176429270372 train_accur =  0.9661458333333334 test_accur =  0.8236534905224225\n",
      "Epoch :  237 training_loss =  0.21173929216493953 test_loss =  0.5615265762136137 train_accur =  0.9674479166666666 test_accur =  0.8235668053629218\n",
      "Epoch :  238 training_loss =  0.21047539882961988 test_loss =  0.560728472505053 train_accur =  0.9674479166666666 test_accur =  0.8237401756819233\n",
      "Epoch :  239 training_loss =  0.20929336795827286 test_loss =  0.5600565081452656 train_accur =  0.9674479166666666 test_accur =  0.8238702034211743\n",
      "Epoch :  240 training_loss =  0.2075254653562169 test_loss =  0.5592334056317126 train_accur =  0.9674479166666666 test_accur =  0.8236390429958391\n",
      "Epoch :  241 training_loss =  0.20584807157354135 test_loss =  0.5585202340828013 train_accur =  0.96875 test_accur =  0.8243325242718447\n",
      "Epoch :  242 training_loss =  0.2046382537745352 test_loss =  0.5578673766284128 train_accur =  0.96875 test_accur =  0.8239713361072585\n",
      "Epoch :  243 training_loss =  0.20344129799553223 test_loss =  0.5570878902507475 train_accur =  0.96875 test_accur =  0.8241736014794268\n",
      "Epoch :  244 training_loss =  0.2022717997109744 test_loss =  0.5563665216534744 train_accur =  0.96875 test_accur =  0.8243614193250116\n",
      "Epoch :  245 training_loss =  0.20128121923412554 test_loss =  0.5556583832795325 train_accur =  0.96875 test_accur =  0.8244914470642626\n",
      "Epoch :  246 training_loss =  0.20036447157455406 test_loss =  0.5550740911615238 train_accur =  0.96875 test_accur =  0.8243903143781784\n",
      "Epoch :  247 training_loss =  0.20000071340208936 test_loss =  0.5539705468139267 train_accur =  0.96875 test_accur =  0.8249537679149329\n",
      "Epoch :  248 training_loss =  0.19866263887254984 test_loss =  0.5534412104344356 train_accur =  0.96875 test_accur =  0.824664817383264\n",
      "Epoch :  249 training_loss =  0.1975795372925818 test_loss =  0.5527801560518287 train_accur =  0.9700520833333334 test_accur =  0.824505894590846\n",
      "Epoch :  250 training_loss =  0.19660691753600446 test_loss =  0.5521821446709696 train_accur =  0.9700520833333334 test_accur =  0.8246070272769301\n",
      "Epoch :  251 training_loss =  0.1956174347230608 test_loss =  0.551503911067875 train_accur =  0.9700520833333334 test_accur =  0.8246214748035137\n",
      "Epoch :  252 training_loss =  0.19460332079722809 test_loss =  0.5507810669792484 train_accur =  0.9700520833333334 test_accur =  0.8246070272769301\n",
      "Epoch :  253 training_loss =  0.19353072650506756 test_loss =  0.5501506461566361 train_accur =  0.9700520833333334 test_accur =  0.8244336569579288\n",
      "Epoch :  254 training_loss =  0.19234479140293073 test_loss =  0.5495263948969075 train_accur =  0.9700520833333334 test_accur =  0.824245839112344\n",
      "Epoch :  255 training_loss =  0.19149454579880126 test_loss =  0.5487824214490324 train_accur =  0.9700520833333334 test_accur =  0.8243469717984281\n",
      "Epoch :  256 training_loss =  0.1903992522159919 test_loss =  0.5481093912125827 train_accur =  0.9700520833333334 test_accur =  0.8244769995376792\n",
      "Epoch :  257 training_loss =  0.1894531624606098 test_loss =  0.5474576928492059 train_accur =  0.9713541666666666 test_accur =  0.824664817383264\n",
      "Epoch :  258 training_loss =  0.1883822011613166 test_loss =  0.5468011136570285 train_accur =  0.9713541666666666 test_accur =  0.8246359223300971\n",
      "Epoch :  259 training_loss =  0.1874504504265292 test_loss =  0.5462171718666466 train_accur =  0.9713541666666666 test_accur =  0.8244625520110958\n",
      "Epoch :  260 training_loss =  0.18651180994812222 test_loss =  0.5455676716753064 train_accur =  0.9713541666666666 test_accur =  0.8243903143781784\n",
      "Epoch :  261 training_loss =  0.18555026824945814 test_loss =  0.5450542295198648 train_accur =  0.9713541666666666 test_accur =  0.8242747341655109\n",
      "Epoch :  262 training_loss =  0.18456697128368846 test_loss =  0.5444730347968693 train_accur =  0.9713541666666666 test_accur =  0.8242891816920943\n",
      "Epoch :  263 training_loss =  0.18365314248621512 test_loss =  0.5438797372818412 train_accur =  0.9713541666666666 test_accur =  0.8243036292186777\n",
      "Epoch :  264 training_loss =  0.18279667890012713 test_loss =  0.5432987195802355 train_accur =  0.9713541666666666 test_accur =  0.8243180767452613\n",
      "Epoch :  265 training_loss =  0.18194620817934154 test_loss =  0.5427687626478864 train_accur =  0.9713541666666666 test_accur =  0.8243180767452613\n",
      "Epoch :  266 training_loss =  0.1811104334675998 test_loss =  0.5421911269505268 train_accur =  0.9713541666666666 test_accur =  0.8243036292186777\n",
      "Epoch :  267 training_loss =  0.1802910203858596 test_loss =  0.5416565279230326 train_accur =  0.9713541666666666 test_accur =  0.824375866851595\n",
      "Epoch :  268 training_loss =  0.179461074416257 test_loss =  0.5411531329141771 train_accur =  0.9713541666666666 test_accur =  0.8244625520110958\n",
      "Epoch :  269 training_loss =  0.17860901671523866 test_loss =  0.5406828090449366 train_accur =  0.9713541666666666 test_accur =  0.824375866851595\n",
      "Epoch :  270 training_loss =  0.17762671494793653 test_loss =  0.5402246221640536 train_accur =  0.9713541666666666 test_accur =  0.824245839112344\n",
      "Epoch :  271 training_loss =  0.1767233042376342 test_loss =  0.539649299807733 train_accur =  0.9713541666666666 test_accur =  0.8244769995376792\n",
      "Epoch :  272 training_loss =  0.17593872025755308 test_loss =  0.5389300052577668 train_accur =  0.9713541666666666 test_accur =  0.824664817383264\n",
      "Epoch :  273 training_loss =  0.1751371352954815 test_loss =  0.5383277365631091 train_accur =  0.9713541666666666 test_accur =  0.8247659500693482\n",
      "Epoch :  274 training_loss =  0.1743425045190149 test_loss =  0.5378425155059223 train_accur =  0.9713541666666666 test_accur =  0.8248237401756819\n",
      "Epoch :  275 training_loss =  0.17354732721164925 test_loss =  0.5373328434397758 train_accur =  0.9713541666666666 test_accur =  0.8248959778085991\n",
      "Epoch :  276 training_loss =  0.17271414092264148 test_loss =  0.5367939420869187 train_accur =  0.9713541666666666 test_accur =  0.8248237401756819\n",
      "Epoch :  277 training_loss =  0.17177869532699994 test_loss =  0.5364907360774495 train_accur =  0.9713541666666666 test_accur =  0.8248526352288488\n",
      "Epoch :  278 training_loss =  0.17083426787660438 test_loss =  0.5359669379578578 train_accur =  0.9713541666666666 test_accur =  0.8247226074895978\n",
      "Epoch :  279 training_loss =  0.1699375480989898 test_loss =  0.5354391023984089 train_accur =  0.9713541666666666 test_accur =  0.8247803975959316\n",
      "Epoch :  280 training_loss =  0.16903862205947684 test_loss =  0.5348973096479233 train_accur =  0.97265625 test_accur =  0.8248381877022654\n",
      "Epoch :  281 training_loss =  0.16800599688861972 test_loss =  0.5343676611954368 train_accur =  0.97265625 test_accur =  0.8249826629680999\n",
      "Epoch :  282 training_loss =  0.16719415055381792 test_loss =  0.5339394885091313 train_accur =  0.97265625 test_accur =  0.8250404530744336\n",
      "Epoch :  283 training_loss =  0.16644158129172062 test_loss =  0.533472410826385 train_accur =  0.97265625 test_accur =  0.8251704808136847\n",
      "Epoch :  284 training_loss =  0.16567344839755757 test_loss =  0.5329956883039013 train_accur =  0.97265625 test_accur =  0.8252716134997689\n",
      "Epoch :  285 training_loss =  0.16483139494517357 test_loss =  0.5325319214667358 train_accur =  0.97265625 test_accur =  0.8253294036061026\n",
      "Epoch :  286 training_loss =  0.16403861670027986 test_loss =  0.5320906709646649 train_accur =  0.97265625 test_accur =  0.8253294036061026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  287 training_loss =  0.16323237028566445 test_loss =  0.5316076023541894 train_accur =  0.97265625 test_accur =  0.8254160887656034\n",
      "Epoch :  288 training_loss =  0.16223410914803918 test_loss =  0.5311478814427653 train_accur =  0.97265625 test_accur =  0.8256183541377716\n",
      "Epoch :  289 training_loss =  0.1618012861697724 test_loss =  0.5305810918073472 train_accur =  0.97265625 test_accur =  0.8254594313453537\n",
      "Epoch :  290 training_loss =  0.16045817617794464 test_loss =  0.5300752198050821 train_accur =  0.97265625 test_accur =  0.825661696717522\n",
      "Epoch :  291 training_loss =  0.15974215874122027 test_loss =  0.5296028078539154 train_accur =  0.97265625 test_accur =  0.825791724456773\n",
      "Epoch :  292 training_loss =  0.15907425687260154 test_loss =  0.529163233710972 train_accur =  0.97265625 test_accur =  0.8259073046694406\n",
      "Epoch :  293 training_loss =  0.15837123449325882 test_loss =  0.5286975824421852 train_accur =  0.97265625 test_accur =  0.8260084373555248\n",
      "Epoch :  294 training_loss =  0.15766245980804033 test_loss =  0.5282576087322514 train_accur =  0.97265625 test_accur =  0.8261529126213593\n",
      "Epoch :  295 training_loss =  0.15694321551470775 test_loss =  0.5278458624016839 train_accur =  0.97265625 test_accur =  0.826210702727693\n",
      "Epoch :  296 training_loss =  0.15620095621058738 test_loss =  0.5273919285051688 train_accur =  0.97265625 test_accur =  0.8263262829403606\n",
      "Epoch :  297 training_loss =  0.15551545342959316 test_loss =  0.5269502375095722 train_accur =  0.97265625 test_accur =  0.8264707582061951\n",
      "Epoch :  298 training_loss =  0.15487501253796215 test_loss =  0.5264972111722814 train_accur =  0.97265625 test_accur =  0.8266152334720296\n",
      "Epoch :  299 training_loss =  0.15424839839335241 test_loss =  0.5260532124119998 train_accur =  0.97265625 test_accur =  0.8267308136846971\n",
      "Epoch :  300 training_loss =  0.15362973327358737 test_loss =  0.5256087414195058 train_accur =  0.97265625 test_accur =  0.8269330790568654\n",
      "Epoch :  301 training_loss =  0.1530147231780153 test_loss =  0.525161806984034 train_accur =  0.97265625 test_accur =  0.8269619741100324\n",
      "Epoch :  302 training_loss =  0.15239790613962134 test_loss =  0.5247793968777725 train_accur =  0.9739583333333334 test_accur =  0.8270920018492834\n",
      "Epoch :  303 training_loss =  0.15187343026713507 test_loss =  0.5243307516195072 train_accur =  0.9752604166666666 test_accur =  0.8271208969024503\n",
      "Epoch :  304 training_loss =  0.15116705976666261 test_loss =  0.5238474379034794 train_accur =  0.9752604166666666 test_accur =  0.827207582061951\n",
      "Epoch :  305 training_loss =  0.15053295966234564 test_loss =  0.5234307858400935 train_accur =  0.9752604166666666 test_accur =  0.827467637540453\n",
      "Epoch :  306 training_loss =  0.14985904782579104 test_loss =  0.5230006545466162 train_accur =  0.9752604166666666 test_accur =  0.8275976652797041\n",
      "Epoch :  307 training_loss =  0.14921713908760392 test_loss =  0.5226380369138687 train_accur =  0.9752604166666666 test_accur =  0.8275832177531207\n",
      "Epoch :  308 training_loss =  0.1485785789587514 test_loss =  0.5222635819217732 train_accur =  0.9752604166666666 test_accur =  0.8274820850670366\n",
      "Epoch :  309 training_loss =  0.14789785989129714 test_loss =  0.5219026532237078 train_accur =  0.9752604166666666 test_accur =  0.8275832177531207\n",
      "Epoch :  310 training_loss =  0.14748886360933638 test_loss =  0.5214571076205305 train_accur =  0.9765625 test_accur =  0.8276410078594545\n",
      "Epoch :  311 training_loss =  0.1466425926737543 test_loss =  0.5211459204159119 train_accur =  0.9765625 test_accur =  0.8275687702265372\n",
      "Epoch :  312 training_loss =  0.14601977974735178 test_loss =  0.5207698444766549 train_accur =  0.9765625 test_accur =  0.8276699029126213\n",
      "Epoch :  313 training_loss =  0.14543126041879548 test_loss =  0.5203981433658188 train_accur =  0.9765625 test_accur =  0.8276843504392049\n",
      "Epoch :  314 training_loss =  0.14498684695977057 test_loss =  0.520204410915097 train_accur =  0.9765625 test_accur =  0.827756588072122\n",
      "Epoch :  315 training_loss =  0.1445389200331967 test_loss =  0.5193637834677972 train_accur =  0.9765625 test_accur =  0.8278432732316228\n",
      "Epoch :  316 training_loss =  0.14374979927972475 test_loss =  0.5191109220419586 train_accur =  0.9765625 test_accur =  0.8278288257050394\n",
      "Epoch :  317 training_loss =  0.14287364604542668 test_loss =  0.5187729581087664 train_accur =  0.9765625 test_accur =  0.8278432732316228\n",
      "Epoch :  318 training_loss =  0.14228167281499687 test_loss =  0.5184008716360553 train_accur =  0.9765625 test_accur =  0.8280021960240407\n",
      "Epoch :  319 training_loss =  0.1417199470047403 test_loss =  0.5180322952493744 train_accur =  0.9765625 test_accur =  0.8280599861303745\n",
      "Epoch :  320 training_loss =  0.14117453113627637 test_loss =  0.5176501159456076 train_accur =  0.9765625 test_accur =  0.8280744336569579\n",
      "Epoch :  321 training_loss =  0.14063453341552673 test_loss =  0.5172806374082056 train_accur =  0.9765625 test_accur =  0.8281466712898752\n",
      "Epoch :  322 training_loss =  0.14009618461123302 test_loss =  0.5169041412732964 train_accur =  0.9778645833333334 test_accur =  0.8280888811835414\n",
      "Epoch :  323 training_loss =  0.13951663756766297 test_loss =  0.5165651520987071 train_accur =  0.9778645833333334 test_accur =  0.828204461396209\n",
      "Epoch :  324 training_loss =  0.13895430010079587 test_loss =  0.5162535057022775 train_accur =  0.9778645833333334 test_accur =  0.8280744336569579\n",
      "Epoch :  325 training_loss =  0.13838848860821218 test_loss =  0.5158969876410636 train_accur =  0.9778645833333334 test_accur =  0.8280744336569579\n",
      "Epoch :  326 training_loss =  0.13783152569073429 test_loss =  0.5155579913366283 train_accur =  0.9778645833333334 test_accur =  0.8282478039759593\n",
      "Epoch :  327 training_loss =  0.13728844798176654 test_loss =  0.5151978420075657 train_accur =  0.9778645833333334 test_accur =  0.8282333564493759\n",
      "Epoch :  328 training_loss =  0.13675768649403386 test_loss =  0.5148776559686488 train_accur =  0.9778645833333334 test_accur =  0.8283200416088765\n",
      "Epoch :  329 training_loss =  0.1362540616944956 test_loss =  0.514581093105502 train_accur =  0.9791666666666666 test_accur =  0.8284500693481276\n",
      "Epoch :  330 training_loss =  0.1357338433864596 test_loss =  0.5142680889517676 train_accur =  0.9791666666666666 test_accur =  0.828493411927878\n",
      "Epoch :  331 training_loss =  0.1352063408280241 test_loss =  0.5139170281010219 train_accur =  0.9791666666666666 test_accur =  0.8285078594544614\n",
      "Epoch :  332 training_loss =  0.13468224379264582 test_loss =  0.5136023376469928 train_accur =  0.9791666666666666 test_accur =  0.828623439667129\n",
      "Epoch :  333 training_loss =  0.1341380284409678 test_loss =  0.513289685007303 train_accur =  0.9791666666666666 test_accur =  0.8286378871937125\n",
      "Epoch :  334 training_loss =  0.1336047022438194 test_loss =  0.512980146835412 train_accur =  0.9791666666666666 test_accur =  0.8285223069810449\n",
      "Epoch :  335 training_loss =  0.1331022042705034 test_loss =  0.5126602030884125 train_accur =  0.9791666666666666 test_accur =  0.8285512020342117\n",
      "Epoch :  336 training_loss =  0.13259949979994184 test_loss =  0.5123557889118587 train_accur =  0.9791666666666666 test_accur =  0.8284789644012945\n",
      "Epoch :  337 training_loss =  0.13211521789366087 test_loss =  0.511985844150936 train_accur =  0.9791666666666666 test_accur =  0.8284500693481276\n",
      "Epoch :  338 training_loss =  0.13161909986024356 test_loss =  0.5117067746158571 train_accur =  0.98046875 test_accur =  0.8284067267683772\n",
      "Epoch :  339 training_loss =  0.131122813110022 test_loss =  0.5114216919446981 train_accur =  0.98046875 test_accur =  0.8284500693481276\n",
      "Epoch :  340 training_loss =  0.1306505858389651 test_loss =  0.5111355584502699 train_accur =  0.98046875 test_accur =  0.8284211742949606\n",
      "Epoch :  341 training_loss =  0.13014783164836574 test_loss =  0.5108198041150981 train_accur =  0.98046875 test_accur =  0.8284067267683772\n",
      "Epoch :  342 training_loss =  0.12966087606172108 test_loss =  0.5105046096226946 train_accur =  0.98046875 test_accur =  0.8283922792417938\n",
      "Epoch :  343 training_loss =  0.12917644576689294 test_loss =  0.5102301722826323 train_accur =  0.9817708333333334 test_accur =  0.8283922792417938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  344 training_loss =  0.1288750879466272 test_loss =  0.5101138204745327 train_accur =  0.9817708333333334 test_accur =  0.8284211742949606\n",
      "Epoch :  345 training_loss =  0.12822197919609468 test_loss =  0.5094592324481269 train_accur =  0.9830729166666666 test_accur =  0.8285512020342117\n",
      "Epoch :  346 training_loss =  0.1277233501725179 test_loss =  0.5091482158165046 train_accur =  0.984375 test_accur =  0.8286523347202959\n",
      "Epoch :  347 training_loss =  0.1272178658588114 test_loss =  0.508863337844746 train_accur =  0.9856770833333334 test_accur =  0.8287390198797966\n",
      "Epoch :  348 training_loss =  0.12672001948096145 test_loss =  0.5085940627648619 train_accur =  0.9856770833333334 test_accur =  0.82875346740638\n",
      "Epoch :  349 training_loss =  0.126234502626304 test_loss =  0.5083104726920168 train_accur =  0.9856770833333334 test_accur =  0.8287679149329634\n",
      "Epoch :  350 training_loss =  0.12577185144527886 test_loss =  0.5080214124687561 train_accur =  0.9856770833333334 test_accur =  0.8287679149329634\n",
      "Epoch :  351 training_loss =  0.12529239905480194 test_loss =  0.5077189103238119 train_accur =  0.9856770833333334 test_accur =  0.8288834951456311\n",
      "Epoch :  352 training_loss =  0.12486103815090266 test_loss =  0.5073893033553181 train_accur =  0.9856770833333334 test_accur =  0.8289123901987979\n",
      "Epoch :  353 training_loss =  0.12440569497397522 test_loss =  0.5070573076706264 train_accur =  0.9856770833333334 test_accur =  0.8288112575127138\n",
      "Epoch :  354 training_loss =  0.12383432597286143 test_loss =  0.5068800323098229 train_accur =  0.9856770833333334 test_accur =  0.8288546000924641\n",
      "Epoch :  355 training_loss =  0.12335323752375929 test_loss =  0.5066653864148454 train_accur =  0.9856770833333334 test_accur =  0.8288112575127138\n",
      "Epoch :  356 training_loss =  0.12289887576996894 test_loss =  0.5064600332723789 train_accur =  0.9856770833333334 test_accur =  0.82875346740638\n",
      "Epoch :  357 training_loss =  0.12243947449840882 test_loss =  0.5062548641256921 train_accur =  0.9869791666666666 test_accur =  0.8287968099861304\n",
      "Epoch :  358 training_loss =  0.12185931378014425 test_loss =  0.506051824128482 train_accur =  0.9869791666666666 test_accur =  0.828782362459547\n",
      "Epoch :  359 training_loss =  0.12107489454455794 test_loss =  0.5057659792661245 train_accur =  0.9869791666666666 test_accur =  0.8287968099861304\n",
      "Epoch :  360 training_loss =  0.12062496074282067 test_loss =  0.5055092065500356 train_accur =  0.9869791666666666 test_accur =  0.8288979426722145\n",
      "Epoch :  361 training_loss =  0.1201803197328983 test_loss =  0.5052546437824106 train_accur =  0.9869791666666666 test_accur =  0.8289557327785483\n",
      "Epoch :  362 training_loss =  0.11971716430825462 test_loss =  0.5050484475922128 train_accur =  0.9869791666666666 test_accur =  0.829071312991216\n",
      "Epoch :  363 training_loss =  0.11921639650430788 test_loss =  0.5048107087496823 train_accur =  0.9869791666666666 test_accur =  0.8291146555709662\n",
      "Epoch :  364 training_loss =  0.11863694743448042 test_loss =  0.5045270680638054 train_accur =  0.9869791666666666 test_accur =  0.8291579981507166\n",
      "Epoch :  365 training_loss =  0.11810814991288797 test_loss =  0.504238506596398 train_accur =  0.9869791666666666 test_accur =  0.8291868932038835\n",
      "Epoch :  366 training_loss =  0.1176392899019531 test_loss =  0.5039989891191808 train_accur =  0.9869791666666666 test_accur =  0.8292157882570504\n",
      "Epoch :  367 training_loss =  0.11721437286527221 test_loss =  0.5037513668015087 train_accur =  0.9869791666666666 test_accur =  0.8292880258899676\n",
      "Epoch :  368 training_loss =  0.11679891886557636 test_loss =  0.503513819799252 train_accur =  0.9869791666666666 test_accur =  0.8293024734165511\n",
      "Epoch :  369 training_loss =  0.11638853078086195 test_loss =  0.5033683904844867 train_accur =  0.9869791666666666 test_accur =  0.8293024734165511\n",
      "Epoch :  370 training_loss =  0.1159471649533663 test_loss =  0.5030574324479188 train_accur =  0.9869791666666666 test_accur =  0.8293024734165511\n",
      "Epoch :  371 training_loss =  0.1154902461890712 test_loss =  0.5027987874123991 train_accur =  0.9869791666666666 test_accur =  0.8293602635228848\n",
      "Epoch :  372 training_loss =  0.11501284271220946 test_loss =  0.5025433678952399 train_accur =  0.9869791666666666 test_accur =  0.8293602635228848\n",
      "Epoch :  373 training_loss =  0.1145885023523077 test_loss =  0.502297149437802 train_accur =  0.9869791666666666 test_accur =  0.8293747110494684\n",
      "Epoch :  374 training_loss =  0.11418727938699852 test_loss =  0.5020599586930496 train_accur =  0.9869791666666666 test_accur =  0.8295336338418863\n",
      "Epoch :  375 training_loss =  0.11381297951710558 test_loss =  0.5019406116897149 train_accur =  0.9869791666666666 test_accur =  0.829461396208969\n",
      "Epoch :  376 training_loss =  0.1133964337928149 test_loss =  0.5017421034032126 train_accur =  0.9869791666666666 test_accur =  0.8295625288950532\n",
      "Epoch :  377 training_loss =  0.11297510964118122 test_loss =  0.501416413064607 train_accur =  0.9869791666666666 test_accur =  0.8296781091077208\n",
      "Epoch :  378 training_loss =  0.11253707338852194 test_loss =  0.5011578877477066 train_accur =  0.9869791666666666 test_accur =  0.8297358992140546\n",
      "Epoch :  379 training_loss =  0.11213229426579048 test_loss =  0.5009722285801289 train_accur =  0.9869791666666666 test_accur =  0.8298225843735553\n",
      "Epoch :  380 training_loss =  0.11170628833088553 test_loss =  0.5006755292652729 train_accur =  0.9869791666666666 test_accur =  0.8297647942672215\n",
      "Epoch :  381 training_loss =  0.1112697906082894 test_loss =  0.5004458963053985 train_accur =  0.9869791666666666 test_accur =  0.829750346740638\n",
      "Epoch :  382 training_loss =  0.11078130871154675 test_loss =  0.5002147866817549 train_accur =  0.9869791666666666 test_accur =  0.8298225843735553\n",
      "Epoch :  383 training_loss =  0.11026009300833901 test_loss =  0.4999484155392004 train_accur =  0.9869791666666666 test_accur =  0.8297936893203883\n",
      "Epoch :  384 training_loss =  0.10987308953021621 test_loss =  0.49970700356737735 train_accur =  0.9869791666666666 test_accur =  0.8298370319001387\n",
      "Epoch :  385 training_loss =  0.1094377633286346 test_loss =  0.4994751168615667 train_accur =  0.98828125 test_accur =  0.8299237170596394\n",
      "Epoch :  386 training_loss =  0.1090595858628972 test_loss =  0.49928179237345166 train_accur =  0.9895833333333334 test_accur =  0.8300248497457235\n",
      "Epoch :  387 training_loss =  0.1086581681695201 test_loss =  0.49904202423085103 train_accur =  0.9895833333333334 test_accur =  0.8300970873786407\n",
      "Epoch :  388 training_loss =  0.10821267050026673 test_loss =  0.4988241122128178 train_accur =  0.9895833333333334 test_accur =  0.8302415626444752\n",
      "Epoch :  389 training_loss =  0.10776702287209192 test_loss =  0.4985724783682972 train_accur =  0.9895833333333334 test_accur =  0.830299352750809\n",
      "Epoch :  390 training_loss =  0.10730101583895932 test_loss =  0.4983224489850503 train_accur =  0.9895833333333334 test_accur =  0.8303860379103097\n",
      "Epoch :  391 training_loss =  0.10680993736597698 test_loss =  0.4981024439064088 train_accur =  0.9895833333333334 test_accur =  0.8303860379103097\n",
      "Epoch :  392 training_loss =  0.10651804641305347 test_loss =  0.4978945505513744 train_accur =  0.9895833333333334 test_accur =  0.8304149329634767\n",
      "Epoch :  393 training_loss =  0.1060126617303062 test_loss =  0.49767284455156174 train_accur =  0.9895833333333334 test_accur =  0.8304149329634767\n",
      "Epoch :  394 training_loss =  0.1056218878069522 test_loss =  0.49746997069837506 train_accur =  0.9895833333333334 test_accur =  0.8305016181229773\n",
      "Epoch :  395 training_loss =  0.10520638672684696 test_loss =  0.4972726388596339 train_accur =  0.9895833333333334 test_accur =  0.8305738557558946\n",
      "Epoch :  396 training_loss =  0.10480828704508 test_loss =  0.49707409869233893 train_accur =  0.9895833333333334 test_accur =  0.8305738557558946\n",
      "Epoch :  397 training_loss =  0.1044311194069259 test_loss =  0.4968708385972281 train_accur =  0.9895833333333334 test_accur =  0.8306894359685622\n",
      "Epoch :  398 training_loss =  0.10403100252060515 test_loss =  0.4966601414505186 train_accur =  0.9895833333333334 test_accur =  0.8306894359685622\n",
      "Epoch :  399 training_loss =  0.10361833388487518 test_loss =  0.49643817372033816 train_accur =  0.9895833333333334 test_accur =  0.8307183310217291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  400 training_loss =  0.10323354795417393 test_loss =  0.49623461991465473 train_accur =  0.9895833333333334 test_accur =  0.8306605409153953\n",
      "Epoch :  401 training_loss =  0.1028494748963171 test_loss =  0.4960241371877655 train_accur =  0.9895833333333334 test_accur =  0.8307327785483125\n",
      "Epoch :  402 training_loss =  0.10249301215069133 test_loss =  0.4958380735759679 train_accur =  0.9895833333333334 test_accur =  0.8307761211280629\n",
      "Epoch :  403 training_loss =  0.10214458459018921 test_loss =  0.4956425877541129 train_accur =  0.9895833333333334 test_accur =  0.8308194637078132\n",
      "Epoch :  404 training_loss =  0.10178873662282713 test_loss =  0.4954477099145283 train_accur =  0.9895833333333334 test_accur =  0.8309639389736477\n",
      "Epoch :  405 training_loss =  0.10142978906005742 test_loss =  0.4952540626616389 train_accur =  0.9895833333333334 test_accur =  0.831166204345816\n",
      "Epoch :  406 training_loss =  0.10107043240661741 test_loss =  0.4950658420361414 train_accur =  0.9895833333333334 test_accur =  0.8313395746648173\n",
      "Epoch :  407 training_loss =  0.10069076473015617 test_loss =  0.49488352995000534 train_accur =  0.9895833333333334 test_accur =  0.8313251271382339\n",
      "Epoch :  408 training_loss =  0.10025443961011352 test_loss =  0.4946855387201638 train_accur =  0.9895833333333334 test_accur =  0.8313684697179843\n",
      "Epoch :  409 training_loss =  0.09982596171633745 test_loss =  0.4944849151377816 train_accur =  0.9895833333333334 test_accur =  0.8313973647711512\n",
      "Epoch :  410 training_loss =  0.09942693983732877 test_loss =  0.49426436115670913 train_accur =  0.9895833333333334 test_accur =  0.8314262598243181\n",
      "Epoch :  411 training_loss =  0.09898113054586855 test_loss =  0.49409176166608837 train_accur =  0.9895833333333334 test_accur =  0.8314407073509015\n",
      "Epoch :  412 training_loss =  0.09857556563007683 test_loss =  0.4939372995980864 train_accur =  0.9895833333333334 test_accur =  0.8314696024040684\n",
      "Epoch :  413 training_loss =  0.09823087163560854 test_loss =  0.4937718549223062 train_accur =  0.9895833333333334 test_accur =  0.8313973647711512\n",
      "Epoch :  414 training_loss =  0.09789348703766988 test_loss =  0.49359044838829313 train_accur =  0.9895833333333334 test_accur =  0.8313106796116505\n",
      "Epoch :  415 training_loss =  0.09756578876645808 test_loss =  0.4934091241132345 train_accur =  0.9895833333333334 test_accur =  0.8312528895053167\n",
      "Epoch :  416 training_loss =  0.09724441231622367 test_loss =  0.49323977852182566 train_accur =  0.9908854166666666 test_accur =  0.8312673370319001\n",
      "Epoch :  417 training_loss =  0.09693400696853224 test_loss =  0.4930865890681855 train_accur =  0.9908854166666666 test_accur =  0.8312528895053167\n",
      "Epoch :  418 training_loss =  0.09662057193072471 test_loss =  0.492905829731371 train_accur =  0.9908854166666666 test_accur =  0.8313251271382339\n",
      "Epoch :  419 training_loss =  0.09630853544538709 test_loss =  0.4927078102415285 train_accur =  0.9908854166666666 test_accur =  0.8314407073509015\n",
      "Epoch :  420 training_loss =  0.09600581117501607 test_loss =  0.4925282488792788 train_accur =  0.9908854166666666 test_accur =  0.8314840499306518\n",
      "Epoch :  421 training_loss =  0.09570246584625289 test_loss =  0.4923516062405095 train_accur =  0.9908854166666666 test_accur =  0.8314840499306518\n",
      "Epoch :  422 training_loss =  0.09539796121585567 test_loss =  0.49218102674260467 train_accur =  0.9908854166666666 test_accur =  0.8315273925104022\n",
      "Epoch :  423 training_loss =  0.09509156144336772 test_loss =  0.4920115808204936 train_accur =  0.9908854166666666 test_accur =  0.8314840499306518\n",
      "Epoch :  424 training_loss =  0.09478269165475342 test_loss =  0.4918393758776335 train_accur =  0.9908854166666666 test_accur =  0.8314840499306518\n",
      "Epoch :  425 training_loss =  0.09447825196466891 test_loss =  0.49165911227640063 train_accur =  0.9908854166666666 test_accur =  0.8315418400369856\n",
      "Epoch :  426 training_loss =  0.09435428488555182 test_loss =  0.4914999063027136 train_accur =  0.9908854166666666 test_accur =  0.8315562875635691\n",
      "Epoch :  427 training_loss =  0.09387916225023374 test_loss =  0.49132497218181 train_accur =  0.9908854166666666 test_accur =  0.831585182616736\n",
      "Epoch :  428 training_loss =  0.09358787385661832 test_loss =  0.4911636962991963 train_accur =  0.9908854166666666 test_accur =  0.8314840499306518\n",
      "Epoch :  429 training_loss =  0.09329856078535959 test_loss =  0.49103237212892 train_accur =  0.9908854166666666 test_accur =  0.8314262598243181\n",
      "Epoch :  430 training_loss =  0.09301337503549491 test_loss =  0.49088297775717676 train_accur =  0.9908854166666666 test_accur =  0.8313540221914009\n",
      "Epoch :  431 training_loss =  0.09273643284537622 test_loss =  0.49071853912563285 train_accur =  0.9908854166666666 test_accur =  0.8313829172445677\n",
      "Epoch :  432 training_loss =  0.09245883176417388 test_loss =  0.49055786858090356 train_accur =  0.9908854166666666 test_accur =  0.8314407073509015\n",
      "Epoch :  433 training_loss =  0.09218280356420769 test_loss =  0.49039477273506615 train_accur =  0.9908854166666666 test_accur =  0.8314984974572354\n",
      "Epoch :  434 training_loss =  0.09190736967497795 test_loss =  0.490230648627796 train_accur =  0.9908854166666666 test_accur =  0.8314696024040684\n",
      "Epoch :  435 training_loss =  0.09163225711423578 test_loss =  0.49006627049065543 train_accur =  0.9908854166666666 test_accur =  0.8314118122977346\n",
      "Epoch :  436 training_loss =  0.09135712043458064 test_loss =  0.48990561224844353 train_accur =  0.9908854166666666 test_accur =  0.8313973647711512\n",
      "Epoch :  437 training_loss =  0.0910805015207698 test_loss =  0.48976534510967307 train_accur =  0.9908854166666666 test_accur =  0.8314984974572354\n",
      "Epoch :  438 training_loss =  0.09080123683258043 test_loss =  0.4896212338317244 train_accur =  0.9908854166666666 test_accur =  0.8315418400369856\n",
      "Epoch :  439 training_loss =  0.09051338581834709 test_loss =  0.48946596397256403 train_accur =  0.9921875 test_accur =  0.8314984974572354\n",
      "Epoch :  440 training_loss =  0.09020447953443439 test_loss =  0.4892941315220419 train_accur =  0.9921875 test_accur =  0.8314262598243181\n",
      "Epoch :  441 training_loss =  0.08987142483123797 test_loss =  0.4891505416010371 train_accur =  0.9921875 test_accur =  0.8313540221914009\n",
      "Epoch :  442 training_loss =  0.08957544810796798 test_loss =  0.48901701204171133 train_accur =  0.9921875 test_accur =  0.8315129449838188\n",
      "Epoch :  443 training_loss =  0.08931579282394612 test_loss =  0.488866662657829 train_accur =  0.9921875 test_accur =  0.8314840499306518\n",
      "Epoch :  444 training_loss =  0.08901232597919878 test_loss =  0.48869259572499585 train_accur =  0.9921875 test_accur =  0.8314840499306518\n",
      "Epoch :  445 training_loss =  0.08873220636202464 test_loss =  0.48851001217871576 train_accur =  0.9921875 test_accur =  0.8314984974572354\n",
      "Epoch :  446 training_loss =  0.08845865916010606 test_loss =  0.4883389301780661 train_accur =  0.9921875 test_accur =  0.8314984974572354\n",
      "Epoch :  447 training_loss =  0.08818943182951161 test_loss =  0.488197206125758 train_accur =  0.9921875 test_accur =  0.8314840499306518\n",
      "Epoch :  448 training_loss =  0.08792458631972913 test_loss =  0.48807357186407674 train_accur =  0.9921875 test_accur =  0.8315273925104022\n",
      "Epoch :  449 training_loss =  0.08766999588976154 test_loss =  0.4879435635497353 train_accur =  0.9921875 test_accur =  0.8315562875635691\n",
      "Epoch :  450 training_loss =  0.08741426386534078 test_loss =  0.4877184348707981 train_accur =  0.9921875 test_accur =  0.8316140776699029\n",
      "Epoch :  451 training_loss =  0.08714619401436954 test_loss =  0.4876279130744686 train_accur =  0.9921875 test_accur =  0.8316285251964863\n",
      "Epoch :  452 training_loss =  0.08689941444938955 test_loss =  0.48749426605306895 train_accur =  0.9921875 test_accur =  0.8314696024040684\n",
      "Epoch :  453 training_loss =  0.0866583804069713 test_loss =  0.48738983797954916 train_accur =  0.9921875 test_accur =  0.8314118122977346\n",
      "Epoch :  454 training_loss =  0.08639812126996857 test_loss =  0.4872941304038819 train_accur =  0.9921875 test_accur =  0.8314407073509015\n",
      "Epoch :  455 training_loss =  0.08614515057608368 test_loss =  0.4871916658402161 train_accur =  0.9921875 test_accur =  0.8316574202496533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  456 training_loss =  0.08589542016623486 test_loss =  0.48710407157376556 train_accur =  0.9921875 test_accur =  0.8317730004623208\n",
      "Epoch :  457 training_loss =  0.08564192798279159 test_loss =  0.48703239198762016 train_accur =  0.9921875 test_accur =  0.8318452380952381\n",
      "Epoch :  458 training_loss =  0.08537409633246333 test_loss =  0.48682917876580556 train_accur =  0.9921875 test_accur =  0.8318596856218216\n",
      "Epoch :  459 training_loss =  0.08506390152933524 test_loss =  0.4867540368408986 train_accur =  0.9921875 test_accur =  0.8319319232547387\n",
      "Epoch :  460 training_loss =  0.08475955549950183 test_loss =  0.4866306179607879 train_accur =  0.9921875 test_accur =  0.832004160887656\n",
      "Epoch :  461 training_loss =  0.08449949041771329 test_loss =  0.4865346056995603 train_accur =  0.9921875 test_accur =  0.8320619509939898\n",
      "Epoch :  462 training_loss =  0.08424791111999441 test_loss =  0.4863797100963739 train_accur =  0.9921875 test_accur =  0.8321486361534906\n",
      "Epoch :  463 training_loss =  0.08400108036746898 test_loss =  0.48624050536119956 train_accur =  0.9921875 test_accur =  0.8321919787332409\n",
      "Epoch :  464 training_loss =  0.08375814875821354 test_loss =  0.48610460022628843 train_accur =  0.9921875 test_accur =  0.8321197411003236\n",
      "Epoch :  465 training_loss =  0.0835217141722766 test_loss =  0.48597182574386977 train_accur =  0.9921875 test_accur =  0.8321775312066574\n",
      "Epoch :  466 training_loss =  0.08327819496533861 test_loss =  0.4858282931442845 train_accur =  0.9921875 test_accur =  0.8322208737864077\n",
      "Epoch :  467 training_loss =  0.08304203707044609 test_loss =  0.48567709410072013 train_accur =  0.9921875 test_accur =  0.8322642163661581\n",
      "Epoch :  468 training_loss =  0.08279089836903898 test_loss =  0.485518775313549 train_accur =  0.9921875 test_accur =  0.8323797965788257\n",
      "Epoch :  469 training_loss =  0.08254749380318066 test_loss =  0.4853632410451452 train_accur =  0.9921875 test_accur =  0.8324375866851595\n",
      "Epoch :  470 training_loss =  0.08230333442927994 test_loss =  0.48522812134939397 train_accur =  0.9921875 test_accur =  0.832452034211743\n",
      "Epoch :  471 training_loss =  0.08206309026862439 test_loss =  0.48510384215415214 train_accur =  0.9921875 test_accur =  0.8325098243180767\n",
      "Epoch :  472 training_loss =  0.08182541567903634 test_loss =  0.48495745648270205 train_accur =  0.9921875 test_accur =  0.8325531668978271\n",
      "Epoch :  473 training_loss =  0.08159412328777642 test_loss =  0.4847937846383013 train_accur =  0.9921875 test_accur =  0.8326687471104947\n",
      "Epoch :  474 training_loss =  0.08135637882536552 test_loss =  0.48465717014858256 train_accur =  0.9934895833333334 test_accur =  0.8327987748497457\n",
      "Epoch :  475 training_loss =  0.08112200797137209 test_loss =  0.48451210855184673 train_accur =  0.9947916666666666 test_accur =  0.8327987748497457\n",
      "Epoch :  476 training_loss =  0.0808907823975742 test_loss =  0.48438425995350365 train_accur =  0.9947916666666666 test_accur =  0.832712089690245\n",
      "Epoch :  477 training_loss =  0.08066220273512797 test_loss =  0.48427699782247136 train_accur =  0.9947916666666666 test_accur =  0.8326976421636616\n",
      "Epoch :  478 training_loss =  0.08043563869591935 test_loss =  0.48416284184783726 train_accur =  0.9947916666666666 test_accur =  0.8326687471104947\n",
      "Epoch :  479 training_loss =  0.08021097474040895 test_loss =  0.4840431464366314 train_accur =  0.9947916666666666 test_accur =  0.8326831946370782\n",
      "Epoch :  480 training_loss =  0.07998629081113218 test_loss =  0.4839269187744514 train_accur =  0.9947916666666666 test_accur =  0.8326976421636616\n",
      "Epoch :  481 training_loss =  0.07975714439722997 test_loss =  0.48381888964782427 train_accur =  0.9947916666666666 test_accur =  0.8326976421636616\n",
      "Epoch :  482 training_loss =  0.07952242622286128 test_loss =  0.48371591319868407 train_accur =  0.9947916666666666 test_accur =  0.8327698797965788\n",
      "Epoch :  483 training_loss =  0.07927639491078664 test_loss =  0.48357374386101576 train_accur =  0.9947916666666666 test_accur =  0.8327843273231623\n",
      "Epoch :  484 training_loss =  0.07902908055202729 test_loss =  0.48352467552752787 train_accur =  0.9947916666666666 test_accur =  0.8327843273231623\n",
      "Epoch :  485 training_loss =  0.07879874088701282 test_loss =  0.48352561899977337 train_accur =  0.9947916666666666 test_accur =  0.8326831946370782\n",
      "Epoch :  486 training_loss =  0.0785782147583865 test_loss =  0.4834573981582019 train_accur =  0.9947916666666666 test_accur =  0.8326542995839112\n",
      "Epoch :  487 training_loss =  0.07836637150741317 test_loss =  0.4833970372139284 train_accur =  0.9947916666666666 test_accur =  0.8326542995839112\n",
      "Epoch :  488 training_loss =  0.07815737051140224 test_loss =  0.48329041367578074 train_accur =  0.9947916666666666 test_accur =  0.8327265372168284\n",
      "Epoch :  489 training_loss =  0.07792627853770286 test_loss =  0.4831307564339371 train_accur =  0.9947916666666666 test_accur =  0.8328710124826629\n",
      "Epoch :  490 training_loss =  0.07770475325785238 test_loss =  0.48298102959930145 train_accur =  0.9947916666666666 test_accur =  0.8327698797965788\n",
      "Epoch :  491 training_loss =  0.07748936824464421 test_loss =  0.4828459366400318 train_accur =  0.9947916666666666 test_accur =  0.8328132223763292\n",
      "Epoch :  492 training_loss =  0.0772822127169728 test_loss =  0.4827112398549326 train_accur =  0.9947916666666666 test_accur =  0.8327987748497457\n",
      "Epoch :  493 training_loss =  0.07707274600721437 test_loss =  0.4825666060721916 train_accur =  0.9947916666666666 test_accur =  0.8327554322699954\n",
      "Epoch :  494 training_loss =  0.07686524570955033 test_loss =  0.4824311398224111 train_accur =  0.9947916666666666 test_accur =  0.8328854600092465\n",
      "Epoch :  495 training_loss =  0.07666064382170142 test_loss =  0.4822918334486681 train_accur =  0.9947916666666666 test_accur =  0.8327554322699954\n",
      "Epoch :  496 training_loss =  0.07645653872021367 test_loss =  0.48214712326606535 train_accur =  0.9947916666666666 test_accur =  0.8326542995839112\n",
      "Epoch :  497 training_loss =  0.07625340967128968 test_loss =  0.4820252442044682 train_accur =  0.9947916666666666 test_accur =  0.8326976421636616\n",
      "Epoch :  498 training_loss =  0.07604977056170001 test_loss =  0.48188734070215034 train_accur =  0.9947916666666666 test_accur =  0.832740984743412\n",
      "Epoch :  499 training_loss =  0.07584884994256413 test_loss =  0.48175048238148954 train_accur =  0.9947916666666666 test_accur =  0.8327265372168284\n",
      "Epoch :  500 training_loss =  0.07564329975001828 test_loss =  0.48163236898967626 train_accur =  0.9947916666666666 test_accur =  0.8325242718446602\n",
      "Epoch :  501 training_loss =  0.07543199435569319 test_loss =  0.4815399646422029 train_accur =  0.9947916666666666 test_accur =  0.8325387193712437\n",
      "Epoch :  502 training_loss =  0.07522237515779359 test_loss =  0.4814319127381485 train_accur =  0.9947916666666666 test_accur =  0.8324809292649098\n",
      "Epoch :  503 training_loss =  0.07500835136459902 test_loss =  0.4813106115175745 train_accur =  0.9947916666666666 test_accur =  0.8326831946370782\n",
      "Epoch :  504 training_loss =  0.07478627314989703 test_loss =  0.4811772869689795 train_accur =  0.9947916666666666 test_accur =  0.8328854600092465\n",
      "Epoch :  505 training_loss =  0.07456392239974059 test_loss =  0.48104842722805446 train_accur =  0.9947916666666666 test_accur =  0.8330154877484974\n",
      "Epoch :  506 training_loss =  0.07435416037104763 test_loss =  0.48094831450859743 train_accur =  0.9947916666666666 test_accur =  0.8329721451687471\n",
      "Epoch :  507 training_loss =  0.0741556515122509 test_loss =  0.48081959137751595 train_accur =  0.9947916666666666 test_accur =  0.8330877253814147\n",
      "Epoch :  508 training_loss =  0.073958697138039 test_loss =  0.4806902458860029 train_accur =  0.9947916666666666 test_accur =  0.8331310679611651\n",
      "Epoch :  509 training_loss =  0.0738856395522815 test_loss =  0.4805161624584831 train_accur =  0.9947916666666666 test_accur =  0.8332466481738326\n",
      "Epoch :  510 training_loss =  0.0735816918902549 test_loss =  0.4804043305743343 train_accur =  0.9947916666666666 test_accur =  0.8332033055940823\n",
      "Epoch :  511 training_loss =  0.07337701402606993 test_loss =  0.48026283067439396 train_accur =  0.9947916666666666 test_accur =  0.833289990753583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  512 training_loss =  0.07318225753094622 test_loss =  0.4801326195425453 train_accur =  0.9947916666666666 test_accur =  0.833420018492834\n",
      "Epoch :  513 training_loss =  0.07298878400855618 test_loss =  0.4799992003011782 train_accur =  0.9947916666666666 test_accur =  0.8334344660194175\n",
      "Epoch :  514 training_loss =  0.07279518711047897 test_loss =  0.47987611254773754 train_accur =  0.9947916666666666 test_accur =  0.8335211511789181\n",
      "Epoch :  515 training_loss =  0.07260072141905699 test_loss =  0.4797520435338714 train_accur =  0.9947916666666666 test_accur =  0.8335644937586685\n",
      "Epoch :  516 training_loss =  0.07240385373587749 test_loss =  0.4796452668521742 train_accur =  0.9947916666666666 test_accur =  0.8336656264447526\n",
      "Epoch :  517 training_loss =  0.07220919154521854 test_loss =  0.479544730411491 train_accur =  0.9947916666666666 test_accur =  0.8338245492371706\n",
      "Epoch :  518 training_loss =  0.0720156177652937 test_loss =  0.47944545189680554 train_accur =  0.9947916666666666 test_accur =  0.8338534442903375\n",
      "Epoch :  519 training_loss =  0.07182016060714477 test_loss =  0.4793451119398869 train_accur =  0.9947916666666666 test_accur =  0.8338678918169209\n",
      "Epoch :  520 training_loss =  0.07162393959497915 test_loss =  0.4792480346434698 train_accur =  0.9947916666666666 test_accur =  0.8338534442903375\n",
      "Epoch :  521 training_loss =  0.0714282324900328 test_loss =  0.4791471364227861 train_accur =  0.9947916666666666 test_accur =  0.8338967868700878\n",
      "Epoch :  522 training_loss =  0.07121883752555168 test_loss =  0.4790428489572135 train_accur =  0.9947916666666666 test_accur =  0.8339256819232548\n",
      "Epoch :  523 training_loss =  0.07102351582209773 test_loss =  0.4789317790942429 train_accur =  0.9947916666666666 test_accur =  0.8340268146093389\n",
      "Epoch :  524 training_loss =  0.07083595688447729 test_loss =  0.47880383229937873 train_accur =  0.9947916666666666 test_accur =  0.8340412621359223\n",
      "Epoch :  525 training_loss =  0.07065110308444891 test_loss =  0.47869481735018016 train_accur =  0.9947916666666666 test_accur =  0.8340268146093389\n",
      "Epoch :  526 training_loss =  0.07046744544523022 test_loss =  0.47859889930926647 train_accur =  0.9947916666666666 test_accur =  0.8340412621359223\n",
      "Epoch :  527 training_loss =  0.07028435314191493 test_loss =  0.47851484313855863 train_accur =  0.9947916666666666 test_accur =  0.8340412621359223\n",
      "Epoch :  528 training_loss =  0.07009971222876493 test_loss =  0.4784241205974815 train_accur =  0.9947916666666666 test_accur =  0.8339545769764216\n",
      "Epoch :  529 training_loss =  0.0699084115507358 test_loss =  0.4783116714924442 train_accur =  0.9947916666666666 test_accur =  0.8340701571890893\n",
      "Epoch :  530 training_loss =  0.06970476715420101 test_loss =  0.47820266540935785 train_accur =  0.9947916666666666 test_accur =  0.8341423948220065\n",
      "Epoch :  531 training_loss =  0.0695059235625003 test_loss =  0.4781192541622053 train_accur =  0.9947916666666666 test_accur =  0.8341423948220065\n",
      "Epoch :  532 training_loss =  0.06932159124254685 test_loss =  0.47804072571383 train_accur =  0.9947916666666666 test_accur =  0.8343302126675913\n",
      "Epoch :  533 training_loss =  0.06913629219124653 test_loss =  0.47794244683169496 train_accur =  0.9947916666666666 test_accur =  0.8344313453536755\n",
      "Epoch :  534 training_loss =  0.0689519253044546 test_loss =  0.47784436755000964 train_accur =  0.9947916666666666 test_accur =  0.8343591077207582\n",
      "Epoch :  535 training_loss =  0.06876638533594442 test_loss =  0.4777382642170123 train_accur =  0.9947916666666666 test_accur =  0.8343880027739251\n",
      "Epoch :  536 training_loss =  0.06858465151564103 test_loss =  0.47757574912436723 train_accur =  0.9947916666666666 test_accur =  0.8343735552473417\n",
      "Epoch :  537 training_loss =  0.06840254988588831 test_loss =  0.47751652256083044 train_accur =  0.99609375 test_accur =  0.8343013176144244\n",
      "Epoch :  538 training_loss =  0.06822115658214467 test_loss =  0.4774572605627607 train_accur =  0.99609375 test_accur =  0.834257975034674\n",
      "Epoch :  539 training_loss =  0.0680423192083568 test_loss =  0.4773972552600736 train_accur =  0.99609375 test_accur =  0.834257975034674\n",
      "Epoch :  540 training_loss =  0.06787312643435317 test_loss =  0.477328852532654 train_accur =  0.99609375 test_accur =  0.8342290799815072\n",
      "Epoch :  541 training_loss =  0.06767404698700194 test_loss =  0.477264333774689 train_accur =  0.99609375 test_accur =  0.8341568423485899\n",
      "Epoch :  542 training_loss =  0.06749257114078352 test_loss =  0.4771944188000281 train_accur =  0.99609375 test_accur =  0.8341568423485899\n",
      "Epoch :  543 training_loss =  0.06731779797946708 test_loss =  0.47712408656286615 train_accur =  0.99609375 test_accur =  0.8341568423485899\n",
      "Epoch :  544 training_loss =  0.06715198964333369 test_loss =  0.4770166935303095 train_accur =  0.99609375 test_accur =  0.834286870087841\n",
      "Epoch :  545 training_loss =  0.0669944555091281 test_loss =  0.47691930356170575 train_accur =  0.99609375 test_accur =  0.8342435275080906\n",
      "Epoch :  546 training_loss =  0.06681340686906408 test_loss =  0.4768136380784938 train_accur =  0.99609375 test_accur =  0.8341857374017568\n",
      "Epoch :  547 training_loss =  0.06676255257889056 test_loss =  0.4767694839874669 train_accur =  0.99609375 test_accur =  0.8343157651410079\n",
      "Epoch :  548 training_loss =  0.06653772213426604 test_loss =  0.4766528173140491 train_accur =  0.99609375 test_accur =  0.8342146324549237\n",
      "Epoch :  549 training_loss =  0.066300749335501 test_loss =  0.47655839062386135 train_accur =  0.99609375 test_accur =  0.8341712898751734\n",
      "Epoch :  550 training_loss =  0.06611675321613118 test_loss =  0.47647138783102483 train_accur =  0.99609375 test_accur =  0.8340846047156727\n",
      "Epoch :  551 training_loss =  0.06593760063532389 test_loss =  0.4763860267474021 train_accur =  0.99609375 test_accur =  0.833997919556172\n",
      "Epoch :  552 training_loss =  0.06576188271637118 test_loss =  0.4763011510514767 train_accur =  0.99609375 test_accur =  0.8340412621359223\n",
      "Epoch :  553 training_loss =  0.06558653236597134 test_loss =  0.4762167968867588 train_accur =  0.99609375 test_accur =  0.8340268146093389\n",
      "Epoch :  554 training_loss =  0.06540104404107641 test_loss =  0.476128739757173 train_accur =  0.99609375 test_accur =  0.8340123670827554\n",
      "Epoch :  555 training_loss =  0.06520322573122478 test_loss =  0.47603190002509954 train_accur =  0.99609375 test_accur =  0.8340412621359223\n",
      "Epoch :  556 training_loss =  0.06503134676636538 test_loss =  0.4759415849521337 train_accur =  0.99609375 test_accur =  0.8340123670827554\n",
      "Epoch :  557 training_loss =  0.06486403397122689 test_loss =  0.47585930576222774 train_accur =  0.99609375 test_accur =  0.8340268146093389\n",
      "Epoch :  558 training_loss =  0.06469560939051648 test_loss =  0.4757788461857744 train_accur =  0.99609375 test_accur =  0.8340268146093389\n",
      "Epoch :  559 training_loss =  0.06452283135336069 test_loss =  0.4756964305820079 train_accur =  0.99609375 test_accur =  0.8340701571890893\n",
      "Epoch :  560 training_loss =  0.06433560356807616 test_loss =  0.47561466365270383 train_accur =  0.99609375 test_accur =  0.8340846047156727\n",
      "Epoch :  561 training_loss =  0.06412804055837576 test_loss =  0.4755328234257958 train_accur =  0.99609375 test_accur =  0.8340557096625058\n",
      "Epoch :  562 training_loss =  0.06393902736385566 test_loss =  0.4754588453925649 train_accur =  0.99609375 test_accur =  0.8340412621359223\n",
      "Epoch :  563 training_loss =  0.06376298326584817 test_loss =  0.47538360211172886 train_accur =  0.99609375 test_accur =  0.8340846047156727\n",
      "Epoch :  564 training_loss =  0.06358784066337586 test_loss =  0.47529677274823123 train_accur =  0.99609375 test_accur =  0.8341134997688395\n",
      "Epoch :  565 training_loss =  0.06340512995177701 test_loss =  0.4751976705319989 train_accur =  0.99609375 test_accur =  0.8341568423485899\n",
      "Epoch :  566 training_loss =  0.06319305860125461 test_loss =  0.47510446171815135 train_accur =  0.99609375 test_accur =  0.834257975034674\n",
      "Epoch :  567 training_loss =  0.06300035479317857 test_loss =  0.4750338747389135 train_accur =  0.99609375 test_accur =  0.8343157651410079\n",
      "Epoch :  568 training_loss =  0.06283560150206655 test_loss =  0.4749566236954106 train_accur =  0.99609375 test_accur =  0.8343157651410079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  569 training_loss =  0.06267086828597053 test_loss =  0.47487681589819924 train_accur =  0.99609375 test_accur =  0.8343591077207582\n",
      "Epoch :  570 training_loss =  0.062495973193060446 test_loss =  0.47480346145576535 train_accur =  0.99609375 test_accur =  0.8343735552473417\n",
      "Epoch :  571 training_loss =  0.062332091544701054 test_loss =  0.474736518495351 train_accur =  0.99609375 test_accur =  0.8343735552473417\n",
      "Epoch :  572 training_loss =  0.062192182404756824 test_loss =  0.4746679182204719 train_accur =  0.99609375 test_accur =  0.834416897827092\n",
      "Epoch :  573 training_loss =  0.062033527698105204 test_loss =  0.47460596270001926 train_accur =  0.99609375 test_accur =  0.8346047156726768\n",
      "Epoch :  574 training_loss =  0.0618752691269943 test_loss =  0.4745698183910703 train_accur =  0.99609375 test_accur =  0.8346336107258437\n",
      "Epoch :  575 training_loss =  0.06172003452473278 test_loss =  0.47453934115347923 train_accur =  0.99609375 test_accur =  0.83457582061951\n",
      "Epoch :  576 training_loss =  0.06156955165548737 test_loss =  0.47450084754927546 train_accur =  0.99609375 test_accur =  0.8346047156726768\n",
      "Epoch :  577 training_loss =  0.06142061226237583 test_loss =  0.4744448305869204 train_accur =  0.99609375 test_accur =  0.8346769533055941\n",
      "Epoch :  578 training_loss =  0.06126591893807638 test_loss =  0.4743933354890287 train_accur =  0.99609375 test_accur =  0.8347636384650948\n",
      "Epoch :  579 training_loss =  0.06111418975059213 test_loss =  0.4743481779230416 train_accur =  0.99609375 test_accur =  0.8347636384650948\n",
      "Epoch :  580 training_loss =  0.060961001684341334 test_loss =  0.47430627519086427 train_accur =  0.99609375 test_accur =  0.8347780859916782\n",
      "Epoch :  581 training_loss =  0.060810788840065105 test_loss =  0.47426087706452597 train_accur =  0.99609375 test_accur =  0.8348503236245954\n",
      "Epoch :  582 training_loss =  0.06066384338110237 test_loss =  0.4742245585438692 train_accur =  0.99609375 test_accur =  0.8348936662043458\n",
      "Epoch :  583 training_loss =  0.06051616167854504 test_loss =  0.47420982579322396 train_accur =  0.99609375 test_accur =  0.834864771151179\n",
      "Epoch :  584 training_loss =  0.06036235401518421 test_loss =  0.4741774595983879 train_accur =  0.99609375 test_accur =  0.834864771151179\n",
      "Epoch :  585 training_loss =  0.060196386562801935 test_loss =  0.4741130973016632 train_accur =  0.99609375 test_accur =  0.8348792186777624\n",
      "Epoch :  586 training_loss =  0.060024438602825095 test_loss =  0.4740451983266341 train_accur =  0.99609375 test_accur =  0.8348214285714286\n",
      "Epoch :  587 training_loss =  0.059847074751718375 test_loss =  0.47400354837581965 train_accur =  0.99609375 test_accur =  0.8347058483587609\n",
      "Epoch :  588 training_loss =  0.059692235886174866 test_loss =  0.4739321199825225 train_accur =  0.99609375 test_accur =  0.8347202958853445\n",
      "Epoch :  589 training_loss =  0.059545044774092185 test_loss =  0.4738634821498529 train_accur =  0.99609375 test_accur =  0.8347202958853445\n",
      "Epoch :  590 training_loss =  0.05936923737093328 test_loss =  0.47379575647948097 train_accur =  0.99609375 test_accur =  0.8347780859916782\n",
      "Epoch :  591 training_loss =  0.05922163613452078 test_loss =  0.4737067516966251 train_accur =  0.99609375 test_accur =  0.8348069810448451\n",
      "Epoch :  592 training_loss =  0.05907899182698791 test_loss =  0.47363205454880347 train_accur =  0.99609375 test_accur =  0.8348792186777624\n",
      "Epoch :  593 training_loss =  0.0589371426205494 test_loss =  0.4735588981798472 train_accur =  0.99609375 test_accur =  0.8349370087840962\n",
      "Epoch :  594 training_loss =  0.05879524557272604 test_loss =  0.47348836222662855 train_accur =  0.99609375 test_accur =  0.8349659038372631\n",
      "Epoch :  595 training_loss =  0.05865179408109579 test_loss =  0.4734187817178077 train_accur =  0.9973958333333334 test_accur =  0.8349803513638465\n",
      "Epoch :  596 training_loss =  0.058504180404989344 test_loss =  0.47334603530033376 train_accur =  0.9973958333333334 test_accur =  0.8350236939435969\n",
      "Epoch :  597 training_loss =  0.05834864957508676 test_loss =  0.47327453238583306 train_accur =  0.9973958333333334 test_accur =  0.8350670365233472\n",
      "Epoch :  598 training_loss =  0.058185152895795 test_loss =  0.4732065088827074 train_accur =  0.9973958333333334 test_accur =  0.8350959315765141\n",
      "Epoch :  599 training_loss =  0.05801977835021079 test_loss =  0.47314083768417925 train_accur =  0.9973958333333334 test_accur =  0.8351681692094314\n",
      "Epoch :  600 training_loss =  0.057857664357628534 test_loss =  0.47307638636121946 train_accur =  0.9973958333333334 test_accur =  0.8351826167360148\n",
      "Epoch :  601 training_loss =  0.05770712068164434 test_loss =  0.47301330728183677 train_accur =  0.9973958333333334 test_accur =  0.8351826167360148\n",
      "Epoch :  602 training_loss =  0.05756564917438884 test_loss =  0.47295174094608966 train_accur =  0.9973958333333334 test_accur =  0.8351970642625982\n",
      "Epoch :  603 training_loss =  0.057427822940330074 test_loss =  0.47289091865720434 train_accur =  0.9973958333333334 test_accur =  0.8352259593157652\n",
      "Epoch :  604 training_loss =  0.05729118564761873 test_loss =  0.4728300810845472 train_accur =  0.9973958333333334 test_accur =  0.8352404068423486\n",
      "Epoch :  605 training_loss =  0.05715488518090494 test_loss =  0.47276836810161216 train_accur =  0.9973958333333334 test_accur =  0.835254854368932\n",
      "Epoch :  606 training_loss =  0.05701763088762546 test_loss =  0.4727049055882948 train_accur =  0.9973958333333334 test_accur =  0.8352404068423486\n",
      "Epoch :  607 training_loss =  0.056875430745368036 test_loss =  0.4726428179356798 train_accur =  0.9973958333333334 test_accur =  0.835254854368932\n",
      "Epoch :  608 training_loss =  0.05672019855295375 test_loss =  0.4725900798268053 train_accur =  0.9973958333333334 test_accur =  0.8352693018955155\n",
      "Epoch :  609 training_loss =  0.05652649354336439 test_loss =  0.47254518653150035 train_accur =  0.9973958333333334 test_accur =  0.8352259593157652\n",
      "Epoch :  610 training_loss =  0.056283922748241955 test_loss =  0.47248696818418257 train_accur =  0.9973958333333334 test_accur =  0.8352693018955155\n",
      "Epoch :  611 training_loss =  0.05614799973632249 test_loss =  0.47242680542893073 train_accur =  0.9973958333333334 test_accur =  0.8351970642625982\n",
      "Epoch :  612 training_loss =  0.05601191873053069 test_loss =  0.47236686060193844 train_accur =  0.9973958333333334 test_accur =  0.8351970642625982\n",
      "Epoch :  613 training_loss =  0.055878449116455335 test_loss =  0.47230788054383954 train_accur =  0.9973958333333334 test_accur =  0.8351681692094314\n",
      "Epoch :  614 training_loss =  0.055746191100286474 test_loss =  0.4722490417713518 train_accur =  0.9973958333333334 test_accur =  0.8351537216828478\n",
      "Epoch :  615 training_loss =  0.05561433666071719 test_loss =  0.47219061251732386 train_accur =  0.9973958333333334 test_accur =  0.8351392741562644\n",
      "Epoch :  616 training_loss =  0.05548175694018044 test_loss =  0.47213443292058865 train_accur =  0.9973958333333334 test_accur =  0.835124826629681\n",
      "Epoch :  617 training_loss =  0.055345418908746086 test_loss =  0.47208083846890775 train_accur =  0.9973958333333334 test_accur =  0.835124826629681\n",
      "Epoch :  618 training_loss =  0.055190679085571265 test_loss =  0.4720343758605846 train_accur =  0.9973958333333334 test_accur =  0.8349659038372631\n",
      "Epoch :  619 training_loss =  0.054928313773235385 test_loss =  0.4720053890975925 train_accur =  0.9973958333333334 test_accur =  0.8349225612575127\n",
      "Epoch :  620 training_loss =  0.05464577912469105 test_loss =  0.4719318643120683 train_accur =  0.9973958333333334 test_accur =  0.8349803513638465\n",
      "Epoch :  621 training_loss =  0.05447888239762533 test_loss =  0.4718672061245716 train_accur =  0.9973958333333334 test_accur =  0.8350092464170135\n",
      "Epoch :  622 training_loss =  0.054327680837137265 test_loss =  0.47179819518950383 train_accur =  0.9973958333333334 test_accur =  0.8350092464170135\n",
      "Epoch :  623 training_loss =  0.05419503032384067 test_loss =  0.4717295124211116 train_accur =  0.9973958333333334 test_accur =  0.8349947988904299\n",
      "Epoch :  624 training_loss =  0.05406467616483772 test_loss =  0.4716547494062456 train_accur =  0.9973958333333334 test_accur =  0.8350236939435969\n",
      "Epoch :  625 training_loss =  0.0539381629349119 test_loss =  0.4715755595772874 train_accur =  0.9973958333333334 test_accur =  0.8350381414701803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  626 training_loss =  0.05380995891573939 test_loss =  0.47151599171950265 train_accur =  0.9973958333333334 test_accur =  0.8350092464170135\n",
      "Epoch :  627 training_loss =  0.053680454754710824 test_loss =  0.4714751251805989 train_accur =  0.9973958333333334 test_accur =  0.8349370087840962\n",
      "Epoch :  628 training_loss =  0.05355256636715815 test_loss =  0.47143320797355465 train_accur =  0.9973958333333334 test_accur =  0.834864771151179\n",
      "Epoch :  629 training_loss =  0.053426317919346114 test_loss =  0.47138889495548236 train_accur =  0.9973958333333334 test_accur =  0.8348792186777624\n",
      "Epoch :  630 training_loss =  0.05330219395519183 test_loss =  0.47134230165148505 train_accur =  0.9973958333333334 test_accur =  0.834864771151179\n",
      "Epoch :  631 training_loss =  0.05318182980469929 test_loss =  0.47129633102446433 train_accur =  0.9973958333333334 test_accur =  0.8348069810448451\n",
      "Epoch :  632 training_loss =  0.053063354488506714 test_loss =  0.47126481180924135 train_accur =  0.9973958333333334 test_accur =  0.8347780859916782\n",
      "Epoch :  633 training_loss =  0.052946324012845575 test_loss =  0.4712260632778318 train_accur =  0.9973958333333334 test_accur =  0.8347058483587609\n",
      "Epoch :  634 training_loss =  0.05282876044840257 test_loss =  0.4711804619109178 train_accur =  0.9973958333333334 test_accur =  0.8347058483587609\n",
      "Epoch :  635 training_loss =  0.052711892757085245 test_loss =  0.4711395367791382 train_accur =  0.9973958333333334 test_accur =  0.8347202958853445\n",
      "Epoch :  636 training_loss =  0.05259572208161986 test_loss =  0.47109869537559934 train_accur =  0.9973958333333334 test_accur =  0.8347058483587609\n",
      "Epoch :  637 training_loss =  0.05247826465301194 test_loss =  0.47105754607603184 train_accur =  0.9973958333333334 test_accur =  0.8346914008321775\n",
      "Epoch :  638 training_loss =  0.052359179732602644 test_loss =  0.471023566378414 train_accur =  0.9973958333333334 test_accur =  0.8347347434119279\n",
      "Epoch :  639 training_loss =  0.052238728857002606 test_loss =  0.47099624182059024 train_accur =  0.9973958333333334 test_accur =  0.8347347434119279\n",
      "Epoch :  640 training_loss =  0.05211782327493567 test_loss =  0.4709726497915728 train_accur =  0.9973958333333334 test_accur =  0.83457582061951\n",
      "Epoch :  641 training_loss =  0.05200295500310077 test_loss =  0.47095347857266767 train_accur =  0.9973958333333334 test_accur =  0.8345180305131762\n",
      "Epoch :  642 training_loss =  0.05191953811478692 test_loss =  0.4709766266924721 train_accur =  0.9973958333333334 test_accur =  0.8345324780397596\n",
      "Epoch :  643 training_loss =  0.05178279508952048 test_loss =  0.4707635228276413 train_accur =  0.9973958333333334 test_accur =  0.8344024503005085\n",
      "Epoch :  644 training_loss =  0.05167720919444982 test_loss =  0.470694968364768 train_accur =  0.9973958333333334 test_accur =  0.8346191631992603\n",
      "Epoch :  645 training_loss =  0.05157229996025195 test_loss =  0.47064717199941336 train_accur =  0.9973958333333334 test_accur =  0.8346480582524272\n",
      "Epoch :  646 training_loss =  0.05146531201929852 test_loss =  0.4705892720374591 train_accur =  0.9973958333333334 test_accur =  0.8347347434119279\n",
      "Epoch :  647 training_loss =  0.05135689017794349 test_loss =  0.470530599793676 train_accur =  0.9973958333333334 test_accur =  0.8347780859916782\n",
      "Epoch :  648 training_loss =  0.05124803211743724 test_loss =  0.4704759532833631 train_accur =  0.9973958333333334 test_accur =  0.8348069810448451\n",
      "Epoch :  649 training_loss =  0.05113856896848694 test_loss =  0.4704249607471804 train_accur =  0.9973958333333334 test_accur =  0.8348069810448451\n",
      "Epoch :  650 training_loss =  0.051027992077139116 test_loss =  0.47037796302740154 train_accur =  0.9973958333333334 test_accur =  0.8348069810448451\n",
      "Epoch :  651 training_loss =  0.050915114264417374 test_loss =  0.4703370741556477 train_accur =  0.9973958333333334 test_accur =  0.8347925335182617\n",
      "Epoch :  652 training_loss =  0.05079768652290458 test_loss =  0.47030968738096746 train_accur =  0.9973958333333334 test_accur =  0.8346914008321775\n",
      "Epoch :  653 training_loss =  0.05067343531069962 test_loss =  0.4703030950973224 train_accur =  0.9973958333333334 test_accur =  0.8346914008321775\n",
      "Epoch :  654 training_loss =  0.05054993978666284 test_loss =  0.4701997260009465 train_accur =  0.9973958333333334 test_accur =  0.8346625057790107\n",
      "Epoch :  655 training_loss =  0.0504384320740594 test_loss =  0.4701336506625166 train_accur =  0.9973958333333334 test_accur =  0.8347491909385113\n",
      "Epoch :  656 training_loss =  0.05032574067497375 test_loss =  0.47006620438560204 train_accur =  0.9973958333333334 test_accur =  0.8347780859916782\n",
      "Epoch :  657 training_loss =  0.05021267717346431 test_loss =  0.4699957126960578 train_accur =  0.9973958333333334 test_accur =  0.8347925335182617\n",
      "Epoch :  658 training_loss =  0.05010384559720473 test_loss =  0.46992837044414243 train_accur =  0.9973958333333334 test_accur =  0.8349081137309292\n",
      "Epoch :  659 training_loss =  0.04999629201576078 test_loss =  0.46987040614210157 train_accur =  0.9973958333333334 test_accur =  0.8349659038372631\n",
      "Epoch :  660 training_loss =  0.049889502131035664 test_loss =  0.4698199425716449 train_accur =  0.9973958333333334 test_accur =  0.8349659038372631\n",
      "Epoch :  661 training_loss =  0.04978334091748711 test_loss =  0.4697740507307603 train_accur =  0.9973958333333334 test_accur =  0.8349370087840962\n",
      "Epoch :  662 training_loss =  0.049677758133587276 test_loss =  0.4697330499934157 train_accur =  0.9973958333333334 test_accur =  0.8349947988904299\n",
      "Epoch :  663 training_loss =  0.04957293320360772 test_loss =  0.46969779599557526 train_accur =  0.9973958333333334 test_accur =  0.8350381414701803\n",
      "Epoch :  664 training_loss =  0.049467042246342824 test_loss =  0.46965425410527206 train_accur =  0.9973958333333334 test_accur =  0.8350092464170135\n",
      "Epoch :  665 training_loss =  0.04936183851374705 test_loss =  0.4696126276397813 train_accur =  0.9973958333333334 test_accur =  0.8349947988904299\n",
      "Epoch :  666 training_loss =  0.04925759515484609 test_loss =  0.46957262929821963 train_accur =  0.9973958333333334 test_accur =  0.8349803513638465\n",
      "Epoch :  667 training_loss =  0.049155593600713345 test_loss =  0.46953144261157986 train_accur =  0.9973958333333334 test_accur =  0.8348936662043458\n",
      "Epoch :  668 training_loss =  0.04905047905799611 test_loss =  0.46950717759385635 train_accur =  0.9973958333333334 test_accur =  0.8348936662043458\n",
      "Epoch :  669 training_loss =  0.049072038648365915 test_loss =  0.46945853025067635 train_accur =  0.9973958333333334 test_accur =  0.8348503236245954\n",
      "Epoch :  670 training_loss =  0.04884689137489861 test_loss =  0.4694172991822759 train_accur =  0.9973958333333334 test_accur =  0.8349370087840962\n",
      "Epoch :  671 training_loss =  0.04874522125178575 test_loss =  0.46938062662903934 train_accur =  0.9973958333333334 test_accur =  0.8350092464170135\n",
      "Epoch :  672 training_loss =  0.048641544278706914 test_loss =  0.46934888685133186 train_accur =  0.9973958333333334 test_accur =  0.8349659038372631\n",
      "Epoch :  673 training_loss =  0.04853473338447485 test_loss =  0.46932276780469817 train_accur =  0.9973958333333334 test_accur =  0.8349659038372631\n",
      "Epoch :  674 training_loss =  0.04842411745593765 test_loss =  0.46929916937639216 train_accur =  0.9973958333333334 test_accur =  0.8349514563106796\n",
      "Epoch :  675 training_loss =  0.04831266368953391 test_loss =  0.46927407757062634 train_accur =  0.9973958333333334 test_accur =  0.8349514563106796\n",
      "Epoch :  676 training_loss =  0.048203303153725216 test_loss =  0.4692541505985443 train_accur =  0.9973958333333334 test_accur =  0.8349514563106796\n",
      "Epoch :  677 training_loss =  0.04809236431287977 test_loss =  0.4692491798627705 train_accur =  0.9973958333333334 test_accur =  0.8349081137309292\n",
      "Epoch :  678 training_loss =  0.04797120080763878 test_loss =  0.469259571136066 train_accur =  0.9973958333333334 test_accur =  0.8349225612575127\n",
      "Epoch :  679 training_loss =  0.047832983644431025 test_loss =  0.46925374993470786 train_accur =  0.9973958333333334 test_accur =  0.8349659038372631\n",
      "Epoch :  680 training_loss =  0.04770160890093872 test_loss =  0.4692066730492812 train_accur =  0.9973958333333334 test_accur =  0.8349659038372631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  681 training_loss =  0.04758522171636685 test_loss =  0.4691930260360904 train_accur =  0.9973958333333334 test_accur =  0.8350814840499307\n",
      "Epoch :  682 training_loss =  0.047475466307892 test_loss =  0.46931080890147703 train_accur =  0.9973958333333334 test_accur =  0.8350381414701803\n",
      "Epoch :  683 training_loss =  0.04736876046816753 test_loss =  0.4693185469882767 train_accur =  0.9973958333333334 test_accur =  0.8350814840499307\n",
      "Epoch :  684 training_loss =  0.04726350185605452 test_loss =  0.4691265431472488 train_accur =  0.9973958333333334 test_accur =  0.8351392741562644\n",
      "Epoch :  685 training_loss =  0.047157977768239365 test_loss =  0.469037680108261 train_accur =  0.9973958333333334 test_accur =  0.8351681692094314\n",
      "Epoch :  686 training_loss =  0.047051103700165756 test_loss =  0.46898170220370644 train_accur =  0.9973958333333334 test_accur =  0.8351392741562644\n",
      "Epoch :  687 training_loss =  0.046939826139275255 test_loss =  0.4689350624320719 train_accur =  0.9973958333333334 test_accur =  0.8350959315765141\n",
      "Epoch :  688 training_loss =  0.046814947790730255 test_loss =  0.4688993915328424 train_accur =  0.9973958333333334 test_accur =  0.8351103791030976\n",
      "Epoch :  689 training_loss =  0.04665867221554122 test_loss =  0.46886936701022547 train_accur =  0.9973958333333334 test_accur =  0.8350670365233472\n",
      "Epoch :  690 training_loss =  0.04650259143592764 test_loss =  0.4688211578943763 train_accur =  0.9973958333333334 test_accur =  0.8350092464170135\n",
      "Epoch :  691 training_loss =  0.046382896900752216 test_loss =  0.4687764772645582 train_accur =  0.9973958333333334 test_accur =  0.8348936662043458\n",
      "Epoch :  692 training_loss =  0.04625729860345083 test_loss =  0.4687311441301088 train_accur =  0.9973958333333334 test_accur =  0.834864771151179\n",
      "Epoch :  693 training_loss =  0.04609440549684762 test_loss =  0.4686913340029793 train_accur =  0.9973958333333334 test_accur =  0.834835876098012\n",
      "Epoch :  694 training_loss =  0.0459621597023504 test_loss =  0.4686694514819589 train_accur =  0.9973958333333334 test_accur =  0.8348069810448451\n",
      "Epoch :  695 training_loss =  0.045856634521984754 test_loss =  0.46866799655275626 train_accur =  0.9973958333333334 test_accur =  0.834835876098012\n",
      "Epoch :  696 training_loss =  0.04572847217913018 test_loss =  0.4686878889250067 train_accur =  0.9973958333333334 test_accur =  0.834864771151179\n",
      "Epoch :  697 training_loss =  0.04557046176357142 test_loss =  0.46867269486680313 train_accur =  0.9973958333333334 test_accur =  0.8349514563106796\n",
      "Epoch :  698 training_loss =  0.04546233019904829 test_loss =  0.4686302749049489 train_accur =  0.9973958333333334 test_accur =  0.8350092464170135\n",
      "Epoch :  699 training_loss =  0.045367683878454315 test_loss =  0.4685871367456911 train_accur =  0.9973958333333334 test_accur =  0.8349659038372631\n",
      "Epoch :  700 training_loss =  0.045274501802518824 test_loss =  0.46853048296152755 train_accur =  0.9973958333333334 test_accur =  0.8349803513638465\n",
      "Epoch :  701 training_loss =  0.0451836296552858 test_loss =  0.46840507537841153 train_accur =  0.9973958333333334 test_accur =  0.8350670365233472\n",
      "Epoch :  702 training_loss =  0.04509418756863829 test_loss =  0.46844041787767887 train_accur =  0.9973958333333334 test_accur =  0.8350092464170135\n",
      "Epoch :  703 training_loss =  0.04500471533183626 test_loss =  0.4684273438584049 train_accur =  0.9973958333333334 test_accur =  0.8350525889967637\n",
      "Epoch :  704 training_loss =  0.04491483182701723 test_loss =  0.46840256135958763 train_accur =  0.9973958333333334 test_accur =  0.8350381414701803\n",
      "Epoch :  705 training_loss =  0.04482591102053722 test_loss =  0.46836804842476387 train_accur =  0.9973958333333334 test_accur =  0.8351392741562644\n",
      "Epoch :  706 training_loss =  0.04473781435913722 test_loss =  0.4683399757116001 train_accur =  0.9973958333333334 test_accur =  0.8352404068423486\n",
      "Epoch :  707 training_loss =  0.04464455168804727 test_loss =  0.46832529904444126 train_accur =  0.9973958333333334 test_accur =  0.8352404068423486\n",
      "Epoch :  708 training_loss =  0.04455320336127623 test_loss =  0.4683040568323275 train_accur =  0.9973958333333334 test_accur =  0.8352693018955155\n",
      "Epoch :  709 training_loss =  0.0444610615001388 test_loss =  0.46828089357707103 train_accur =  0.9973958333333334 test_accur =  0.8353559870550162\n",
      "Epoch :  710 training_loss =  0.044366762009541455 test_loss =  0.4682598697743775 train_accur =  0.9973958333333334 test_accur =  0.8353993296347665\n",
      "Epoch :  711 training_loss =  0.04427186378238844 test_loss =  0.4682507501014479 train_accur =  0.9973958333333334 test_accur =  0.8354282246879334\n",
      "Epoch :  712 training_loss =  0.0441819481337877 test_loss =  0.4682500722858719 train_accur =  0.9973958333333334 test_accur =  0.8353848821081831\n",
      "Epoch :  713 training_loss =  0.04408560087486975 test_loss =  0.4681665805018311 train_accur =  0.9973958333333334 test_accur =  0.8353704345815997\n",
      "Epoch :  714 training_loss =  0.04399637107175289 test_loss =  0.4681265890207007 train_accur =  0.9973958333333334 test_accur =  0.83541377716135\n",
      "Epoch :  715 training_loss =  0.0439087338410242 test_loss =  0.46808661648692934 train_accur =  0.9973958333333334 test_accur =  0.8354571197411004\n",
      "Epoch :  716 training_loss =  0.04382211248255243 test_loss =  0.4680436036435476 train_accur =  0.9973958333333334 test_accur =  0.8354571197411004\n",
      "Epoch :  717 training_loss =  0.043736441587890466 test_loss =  0.4679957070716023 train_accur =  0.9973958333333334 test_accur =  0.8355149098474342\n",
      "Epoch :  718 training_loss =  0.043651262124402034 test_loss =  0.46794804885362856 train_accur =  0.9973958333333334 test_accur =  0.8355004623208506\n",
      "Epoch :  719 training_loss =  0.043566307328871824 test_loss =  0.4679045564730738 train_accur =  0.9973958333333334 test_accur =  0.8355293573740176\n",
      "Epoch :  720 training_loss =  0.0434816350279453 test_loss =  0.46786263633052166 train_accur =  0.9973958333333334 test_accur =  0.8355871474803513\n",
      "Epoch :  721 training_loss =  0.043397253716081316 test_loss =  0.4678217951883845 train_accur =  0.9973958333333334 test_accur =  0.8355582524271845\n",
      "Epoch :  722 training_loss =  0.04331315033480439 test_loss =  0.46778156794645276 train_accur =  0.9973958333333334 test_accur =  0.8356160425335183\n",
      "Epoch :  723 training_loss =  0.04322928093186791 test_loss =  0.467741710112731 train_accur =  0.9973958333333334 test_accur =  0.8355726999537679\n",
      "Epoch :  724 training_loss =  0.043145593954625056 test_loss =  0.4677021665517892 train_accur =  0.9973958333333334 test_accur =  0.8355871474803513\n",
      "Epoch :  725 training_loss =  0.04306200347718227 test_loss =  0.46766367121489977 train_accur =  0.9973958333333334 test_accur =  0.8356015950069348\n",
      "Epoch :  726 training_loss =  0.0429783049547094 test_loss =  0.46762836962970306 train_accur =  0.9973958333333334 test_accur =  0.8356304900601017\n",
      "Epoch :  727 training_loss =  0.0428939663070046 test_loss =  0.4675969288574546 train_accur =  0.9973958333333334 test_accur =  0.8356882801664355\n",
      "Epoch :  728 training_loss =  0.042806248226023566 test_loss =  0.4675696052397824 train_accur =  0.9973958333333334 test_accur =  0.835702727693019\n",
      "Epoch :  729 training_loss =  0.04271253264906823 test_loss =  0.4675445033989463 train_accur =  0.9973958333333334 test_accur =  0.8357316227461858\n",
      "Epoch :  730 training_loss =  0.04263114320145661 test_loss =  0.46749267984511084 train_accur =  0.9973958333333334 test_accur =  0.8357605177993528\n",
      "Epoch :  731 training_loss =  0.0425489529347486 test_loss =  0.4674563204536292 train_accur =  0.9973958333333334 test_accur =  0.8357316227461858\n",
      "Epoch :  732 training_loss =  0.04246607835582844 test_loss =  0.4674362077195534 train_accur =  0.9973958333333334 test_accur =  0.8357605177993528\n",
      "Epoch :  733 training_loss =  0.042383083266246485 test_loss =  0.4674137337019479 train_accur =  0.9973958333333334 test_accur =  0.8357749653259362\n",
      "Epoch :  734 training_loss =  0.04230041476852201 test_loss =  0.4673922893993066 train_accur =  0.9973958333333334 test_accur =  0.8357605177993528\n",
      "Epoch :  735 training_loss =  0.04221880716159535 test_loss =  0.4673742207688631 train_accur =  0.9973958333333334 test_accur =  0.8357894128525196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  736 training_loss =  0.04214210112155463 test_loss =  0.467355093347777 train_accur =  0.9973958333333334 test_accur =  0.8358183079056866\n",
      "Epoch :  737 training_loss =  0.042057130900908506 test_loss =  0.4673343142885077 train_accur =  0.9973958333333334 test_accur =  0.8358905455386038\n",
      "Epoch :  738 training_loss =  0.04197145154337537 test_loss =  0.4673123098429361 train_accur =  0.9973958333333334 test_accur =  0.8358905455386038\n",
      "Epoch :  739 training_loss =  0.04188727331460346 test_loss =  0.4672886425996311 train_accur =  0.9973958333333334 test_accur =  0.8358760980120203\n",
      "Epoch :  740 training_loss =  0.041803765855837755 test_loss =  0.4672642848350743 train_accur =  0.9973958333333334 test_accur =  0.8357894128525196\n",
      "Epoch :  741 training_loss =  0.04172058826096059 test_loss =  0.46723999843148584 train_accur =  0.9973958333333334 test_accur =  0.835702727693019\n",
      "Epoch :  742 training_loss =  0.04163747775881274 test_loss =  0.46721644884698327 train_accur =  0.9973958333333334 test_accur =  0.8356738326398521\n",
      "Epoch :  743 training_loss =  0.041554240204226295 test_loss =  0.4671941512543997 train_accur =  0.9973958333333334 test_accur =  0.8356304900601017\n",
      "Epoch :  744 training_loss =  0.041470862209051246 test_loss =  0.46717338732666003 train_accur =  0.9973958333333334 test_accur =  0.835543804900601\n",
      "Epoch :  745 training_loss =  0.04138774818182627 test_loss =  0.4671542928173653 train_accur =  0.9973958333333334 test_accur =  0.8355293573740176\n",
      "Epoch :  746 training_loss =  0.041307008458326716 test_loss =  0.46713654855060777 train_accur =  0.9973958333333334 test_accur =  0.8354426722145168\n",
      "Epoch :  747 training_loss =  0.04124944636476032 test_loss =  0.46710590873861946 train_accur =  0.9973958333333334 test_accur =  0.8353704345815997\n",
      "Epoch :  748 training_loss =  0.04114494927649627 test_loss =  0.46707573902041044 train_accur =  0.9973958333333334 test_accur =  0.8353415395284327\n",
      "Epoch :  749 training_loss =  0.041057287990456215 test_loss =  0.4670680677670733 train_accur =  0.9973958333333334 test_accur =  0.8353270920018493\n",
      "Epoch :  750 training_loss =  0.040970599768821905 test_loss =  0.4670799753899528 train_accur =  0.9973958333333334 test_accur =  0.8353704345815997\n",
      "Epoch :  751 training_loss =  0.04088217142242307 test_loss =  0.46710912866282017 train_accur =  0.9973958333333334 test_accur =  0.8353415395284327\n",
      "Epoch :  752 training_loss =  0.0407846600880358 test_loss =  0.46714599811720275 train_accur =  0.9973958333333334 test_accur =  0.8354282246879334\n",
      "Epoch :  753 training_loss =  0.04067932137475326 test_loss =  0.46712749352405847 train_accur =  0.9973958333333334 test_accur =  0.8353126444752659\n",
      "Epoch :  754 training_loss =  0.040575204616952826 test_loss =  0.4671030924141492 train_accur =  0.9973958333333334 test_accur =  0.8352404068423486\n",
      "Epoch :  755 training_loss =  0.04049130289913751 test_loss =  0.46708758041970544 train_accur =  0.9973958333333334 test_accur =  0.8352259593157652\n",
      "Epoch :  756 training_loss =  0.04041064386205008 test_loss =  0.4670737570193342 train_accur =  0.9973958333333334 test_accur =  0.8351826167360148\n",
      "Epoch :  757 training_loss =  0.04033093040954497 test_loss =  0.46705864344165127 train_accur =  0.9973958333333334 test_accur =  0.8351826167360148\n",
      "Epoch :  758 training_loss =  0.04025166665330039 test_loss =  0.46703878301557283 train_accur =  0.9973958333333334 test_accur =  0.8351392741562644\n",
      "Epoch :  759 training_loss =  0.04017196143939893 test_loss =  0.46700479339391643 train_accur =  0.9973958333333334 test_accur =  0.8351103791030976\n",
      "Epoch :  760 training_loss =  0.040091013189488225 test_loss =  0.4669715791192391 train_accur =  0.9973958333333334 test_accur =  0.8350959315765141\n",
      "Epoch :  761 training_loss =  0.040007453097907424 test_loss =  0.4669397895509563 train_accur =  0.9973958333333334 test_accur =  0.8350959315765141\n",
      "Epoch :  762 training_loss =  0.03992001921478216 test_loss =  0.4669099731358658 train_accur =  0.9973958333333334 test_accur =  0.8351103791030976\n",
      "Epoch :  763 training_loss =  0.0398323360364391 test_loss =  0.46688378935274416 train_accur =  0.9973958333333334 test_accur =  0.8350959315765141\n",
      "Epoch :  764 training_loss =  0.03974890829739592 test_loss =  0.46686047278308584 train_accur =  0.9973958333333334 test_accur =  0.8350959315765141\n",
      "Epoch :  765 training_loss =  0.039668592313140266 test_loss =  0.46683841919935776 train_accur =  0.9973958333333334 test_accur =  0.8350959315765141\n",
      "Epoch :  766 training_loss =  0.039589851726141635 test_loss =  0.4668163977518275 train_accur =  0.9973958333333334 test_accur =  0.8350814840499307\n",
      "Epoch :  767 training_loss =  0.039511943393836776 test_loss =  0.4667929680002073 train_accur =  0.9973958333333334 test_accur =  0.835124826629681\n",
      "Epoch :  768 training_loss =  0.039434488089897045 test_loss =  0.46676761214903856 train_accur =  0.9973958333333334 test_accur =  0.8351826167360148\n",
      "Epoch :  769 training_loss =  0.03935731014060219 test_loss =  0.4667429448043562 train_accur =  0.9973958333333334 test_accur =  0.8351681692094314\n",
      "Epoch :  770 training_loss =  0.039280297796831495 test_loss =  0.4667202220153299 train_accur =  0.9973958333333334 test_accur =  0.8351970642625982\n",
      "Epoch :  771 training_loss =  0.03920340947219326 test_loss =  0.46669904386129435 train_accur =  0.9973958333333334 test_accur =  0.8352404068423486\n",
      "Epoch :  772 training_loss =  0.039126846425118225 test_loss =  0.4666803099312983 train_accur =  0.9973958333333334 test_accur =  0.8352837494220989\n",
      "Epoch :  773 training_loss =  0.0390511015566479 test_loss =  0.46666515210152115 train_accur =  0.9973958333333334 test_accur =  0.8353126444752659\n",
      "Epoch :  774 training_loss =  0.03897599180176855 test_loss =  0.4666441213667036 train_accur =  0.9973958333333334 test_accur =  0.8353993296347665\n",
      "Epoch :  775 training_loss =  0.038901670219169446 test_loss =  0.46661850703249563 train_accur =  0.9973958333333334 test_accur =  0.8353848821081831\n",
      "Epoch :  776 training_loss =  0.03882839739122719 test_loss =  0.46659177171214755 train_accur =  0.9973958333333334 test_accur =  0.8353848821081831\n",
      "Epoch :  777 training_loss =  0.03875597784141013 test_loss =  0.466564913310819 train_accur =  0.9973958333333334 test_accur =  0.8353848821081831\n",
      "Epoch :  778 training_loss =  0.038684174914409605 test_loss =  0.466539653470898 train_accur =  0.9973958333333334 test_accur =  0.8353704345815997\n",
      "Epoch :  779 training_loss =  0.038612834002485115 test_loss =  0.46651759963444783 train_accur =  0.9973958333333334 test_accur =  0.8353704345815997\n",
      "Epoch :  780 training_loss =  0.03854190218223434 test_loss =  0.4664991719117704 train_accur =  0.9973958333333334 test_accur =  0.8353993296347665\n",
      "Epoch :  781 training_loss =  0.03847135407184475 test_loss =  0.46648416369666884 train_accur =  0.9973958333333334 test_accur =  0.8353704345815997\n",
      "Epoch :  782 training_loss =  0.03840111056766051 test_loss =  0.4664718400323684 train_accur =  0.9973958333333334 test_accur =  0.8353993296347665\n",
      "Epoch :  783 training_loss =  0.03833094336016058 test_loss =  0.46646336832238444 train_accur =  0.9973958333333334 test_accur =  0.8353559870550162\n",
      "Epoch :  784 training_loss =  0.03826054836875768 test_loss =  0.4664547650807023 train_accur =  0.9973958333333334 test_accur =  0.8353704345815997\n",
      "Epoch :  785 training_loss =  0.038190196206556865 test_loss =  0.4664460663765852 train_accur =  0.9973958333333334 test_accur =  0.8353415395284327\n",
      "Epoch :  786 training_loss =  0.03812039252772678 test_loss =  0.4664434440374699 train_accur =  0.9973958333333334 test_accur =  0.8352837494220989\n",
      "Epoch :  787 training_loss =  0.03805325634278017 test_loss =  0.4664478055761172 train_accur =  0.9973958333333334 test_accur =  0.8353270920018493\n",
      "Epoch :  788 training_loss =  0.037986366819030414 test_loss =  0.4664389422427537 train_accur =  0.9973958333333334 test_accur =  0.8353126444752659\n",
      "Epoch :  789 training_loss =  0.03790515780513778 test_loss =  0.466412603434923 train_accur =  0.9973958333333334 test_accur =  0.8353126444752659\n",
      "Epoch :  790 training_loss =  0.03781815069669793 test_loss =  0.4663643787068407 train_accur =  0.9973958333333334 test_accur =  0.8352693018955155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  791 training_loss =  0.03773979266564515 test_loss =  0.4663385784689366 train_accur =  0.9973958333333334 test_accur =  0.8352693018955155\n",
      "Epoch :  792 training_loss =  0.037666583712464376 test_loss =  0.4663228989160282 train_accur =  0.9973958333333334 test_accur =  0.835254854368932\n",
      "Epoch :  793 training_loss =  0.03759633636976807 test_loss =  0.4663115265520548 train_accur =  0.9973958333333334 test_accur =  0.8353270920018493\n",
      "Epoch :  794 training_loss =  0.037529002207900994 test_loss =  0.46630510252929736 train_accur =  0.9973958333333334 test_accur =  0.8353559870550162\n",
      "Epoch :  795 training_loss =  0.03746457294071434 test_loss =  0.4663096394705143 train_accur =  0.9973958333333334 test_accur =  0.8353704345815997\n",
      "Epoch :  796 training_loss =  0.03739680055456636 test_loss =  0.46631498021582224 train_accur =  0.9973958333333334 test_accur =  0.8353993296347665\n",
      "Epoch :  797 training_loss =  0.0373287411828586 test_loss =  0.46628886716239953 train_accur =  0.9973958333333334 test_accur =  0.8353848821081831\n",
      "Epoch :  798 training_loss =  0.037261261539516456 test_loss =  0.4662590772063612 train_accur =  0.9973958333333334 test_accur =  0.83541377716135\n",
      "Epoch :  799 training_loss =  0.03719420328896124 test_loss =  0.46623482868215493 train_accur =  0.9973958333333334 test_accur =  0.8354426722145168\n",
      "Epoch :  800 training_loss =  0.03712760044290469 test_loss =  0.46620932180958263 train_accur =  0.9973958333333334 test_accur =  0.8354571197411004\n",
      "Epoch :  801 training_loss =  0.03706149177990784 test_loss =  0.46618763453612294 train_accur =  0.9973958333333334 test_accur =  0.8354715672676838\n",
      "Epoch :  802 training_loss =  0.03699565798597481 test_loss =  0.46616711804132616 train_accur =  0.9973958333333334 test_accur =  0.8354715672676838\n",
      "Epoch :  803 training_loss =  0.03692998272334274 test_loss =  0.4661454595035023 train_accur =  0.9973958333333334 test_accur =  0.8354571197411004\n",
      "Epoch :  804 training_loss =  0.03686436061266178 test_loss =  0.46612341699828824 train_accur =  0.9973958333333334 test_accur =  0.8354715672676838\n",
      "Epoch :  805 training_loss =  0.03679875589982112 test_loss =  0.4661018206251798 train_accur =  0.9973958333333334 test_accur =  0.8355149098474342\n",
      "Epoch :  806 training_loss =  0.03673317368842266 test_loss =  0.4660809960764985 train_accur =  0.9973958333333334 test_accur =  0.835543804900601\n",
      "Epoch :  807 training_loss =  0.03666760679413237 test_loss =  0.46606132896079705 train_accur =  0.9973958333333334 test_accur =  0.835543804900601\n",
      "Epoch :  808 training_loss =  0.03660205515668351 test_loss =  0.46604439144163967 train_accur =  0.9973958333333334 test_accur =  0.8355293573740176\n",
      "Epoch :  809 training_loss =  0.03653673216165425 test_loss =  0.4660343850984537 train_accur =  0.9973958333333334 test_accur =  0.8354860147942672\n",
      "Epoch :  810 training_loss =  0.03647225377469727 test_loss =  0.46603926024132847 train_accur =  0.9973958333333334 test_accur =  0.835543804900601\n",
      "Epoch :  811 training_loss =  0.03641205859790463 test_loss =  0.4660827872322715 train_accur =  0.9973958333333334 test_accur =  0.8356304900601017\n",
      "Epoch :  812 training_loss =  0.03634865672656891 test_loss =  0.46605197255411035 train_accur =  0.9973958333333334 test_accur =  0.8356449375866851\n",
      "Epoch :  813 training_loss =  0.03628591421574003 test_loss =  0.46603220600843337 train_accur =  0.9973958333333334 test_accur =  0.8356449375866851\n",
      "Epoch :  814 training_loss =  0.03622310392489171 test_loss =  0.4660150594775257 train_accur =  0.9973958333333334 test_accur =  0.835702727693019\n",
      "Epoch :  815 training_loss =  0.03616015866630762 test_loss =  0.46600179373729184 train_accur =  0.9973958333333334 test_accur =  0.8357605177993528\n",
      "Epoch :  816 training_loss =  0.03609710619458983 test_loss =  0.46598540463816446 train_accur =  0.9973958333333334 test_accur =  0.8358038603791031\n",
      "Epoch :  817 training_loss =  0.036033990761734705 test_loss =  0.46596925749351353 train_accur =  0.9973958333333334 test_accur =  0.8357605177993528\n",
      "Epoch :  818 training_loss =  0.03597091133933192 test_loss =  0.46595288342677743 train_accur =  0.9973958333333334 test_accur =  0.8357460702727693\n",
      "Epoch :  819 training_loss =  0.035908055536065346 test_loss =  0.4659374775566809 train_accur =  0.9973958333333334 test_accur =  0.8357605177993528\n",
      "Epoch :  820 training_loss =  0.0358455079689651 test_loss =  0.465923534694358 train_accur =  0.9973958333333334 test_accur =  0.8356882801664355\n",
      "Epoch :  821 training_loss =  0.035783220625532394 test_loss =  0.46591117862785775 train_accur =  0.9973958333333334 test_accur =  0.8356449375866851\n",
      "Epoch :  822 training_loss =  0.035721051067480886 test_loss =  0.4659004226876539 train_accur =  0.9973958333333334 test_accur =  0.8356304900601017\n",
      "Epoch :  823 training_loss =  0.03565884167148853 test_loss =  0.46589018309040947 train_accur =  0.9986979166666666 test_accur =  0.8356015950069348\n",
      "Epoch :  824 training_loss =  0.035596846561083015 test_loss =  0.4658808531603271 train_accur =  0.9986979166666666 test_accur =  0.8355871474803513\n",
      "Epoch :  825 training_loss =  0.035535897276007825 test_loss =  0.46587624997833876 train_accur =  0.9986979166666666 test_accur =  0.8356304900601017\n",
      "Epoch :  826 training_loss =  0.035477526684025824 test_loss =  0.4658685183463095 train_accur =  0.9986979166666666 test_accur =  0.8356160425335183\n",
      "Epoch :  827 training_loss =  0.03541298963168815 test_loss =  0.46583943332013655 train_accur =  0.9986979166666666 test_accur =  0.8355726999537679\n",
      "Epoch :  828 training_loss =  0.035349167902190864 test_loss =  0.46581414423821915 train_accur =  0.9986979166666666 test_accur =  0.8355871474803513\n",
      "Epoch :  829 training_loss =  0.03528607141150751 test_loss =  0.46578771453227946 train_accur =  0.9986979166666666 test_accur =  0.8355726999537679\n",
      "Epoch :  830 training_loss =  0.035224207476820195 test_loss =  0.4657454300835368 train_accur =  0.9986979166666666 test_accur =  0.8355582524271845\n",
      "Epoch :  831 training_loss =  0.035163197458228254 test_loss =  0.46571456271027184 train_accur =  0.9986979166666666 test_accur =  0.8355293573740176\n",
      "Epoch :  832 training_loss =  0.035099918192557956 test_loss =  0.4657338513853175 train_accur =  0.9986979166666666 test_accur =  0.8355004623208506\n",
      "Epoch :  833 training_loss =  0.035038544157287056 test_loss =  0.4657461302157755 train_accur =  0.9986979166666666 test_accur =  0.8355149098474342\n",
      "Epoch :  834 training_loss =  0.03497532853758328 test_loss =  0.46573834071311954 train_accur =  0.9986979166666666 test_accur =  0.8356304900601017\n",
      "Epoch :  835 training_loss =  0.034909525186697064 test_loss =  0.4657216463745824 train_accur =  0.9986979166666666 test_accur =  0.8356593851132686\n",
      "Epoch :  836 training_loss =  0.03483996859948567 test_loss =  0.46570471034768085 train_accur =  0.9986979166666666 test_accur =  0.8356015950069348\n",
      "Epoch :  837 training_loss =  0.034767216998808886 test_loss =  0.4656895661496418 train_accur =  0.9986979166666666 test_accur =  0.8355871474803513\n",
      "Epoch :  838 training_loss =  0.0346984152841498 test_loss =  0.4656804198510194 train_accur =  0.9986979166666666 test_accur =  0.8356738326398521\n",
      "Epoch :  839 training_loss =  0.03462934958827847 test_loss =  0.4656831758359527 train_accur =  0.9986979166666666 test_accur =  0.8356304900601017\n",
      "Epoch :  840 training_loss =  0.034537857780061715 test_loss =  0.4657240388289272 train_accur =  0.9986979166666666 test_accur =  0.8356882801664355\n",
      "Epoch :  841 training_loss =  0.03424318157381435 test_loss =  0.46577079838174096 train_accur =  0.9986979166666666 test_accur =  0.8357316227461858\n",
      "Epoch :  842 training_loss =  0.03412121685419452 test_loss =  0.46568992085735506 train_accur =  0.9986979166666666 test_accur =  0.8357460702727693\n",
      "Epoch :  843 training_loss =  0.03406359698273448 test_loss =  0.46565187868552965 train_accur =  0.9986979166666666 test_accur =  0.8358038603791031\n",
      "Epoch :  844 training_loss =  0.034005501598233394 test_loss =  0.46562319665155616 train_accur =  0.9986979166666666 test_accur =  0.8358038603791031\n",
      "Epoch :  845 training_loss =  0.03394772141875402 test_loss =  0.4655980253459079 train_accur =  0.9986979166666666 test_accur =  0.83583275543227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  846 training_loss =  0.03389080448495707 test_loss =  0.4655742183131607 train_accur =  0.9986979166666666 test_accur =  0.83583275543227\n",
      "Epoch :  847 training_loss =  0.03383494172897028 test_loss =  0.4655509654025777 train_accur =  0.9986979166666666 test_accur =  0.83583275543227\n",
      "Epoch :  848 training_loss =  0.03377991754045194 test_loss =  0.4655287364204206 train_accur =  0.9986979166666666 test_accur =  0.8359049930651873\n",
      "Epoch :  849 training_loss =  0.03372537346117161 test_loss =  0.46550755187607423 train_accur =  0.9986979166666666 test_accur =  0.8359049930651873\n",
      "Epoch :  850 training_loss =  0.033671778116085946 test_loss =  0.46548528887018376 train_accur =  0.9986979166666666 test_accur =  0.8359194405917707\n",
      "Epoch :  851 training_loss =  0.033618374676412495 test_loss =  0.46545888502327865 train_accur =  0.9986979166666666 test_accur =  0.8359049930651873\n",
      "Epoch :  852 training_loss =  0.033563512620585 test_loss =  0.4654288111479937 train_accur =  0.9986979166666666 test_accur =  0.8358760980120203\n",
      "Epoch :  853 training_loss =  0.03350748082098698 test_loss =  0.46540990075058913 train_accur =  1.0 test_accur =  0.8358038603791031\n",
      "Epoch :  854 training_loss =  0.0334513263653268 test_loss =  0.4653928083414398 train_accur =  1.0 test_accur =  0.8357749653259362\n",
      "Epoch :  855 training_loss =  0.033395468905550556 test_loss =  0.46537484169335896 train_accur =  1.0 test_accur =  0.8357894128525196\n",
      "Epoch :  856 training_loss =  0.033339814754420466 test_loss =  0.4653567241475459 train_accur =  1.0 test_accur =  0.83583275543227\n",
      "Epoch :  857 training_loss =  0.03328428251955805 test_loss =  0.46534349745148174 train_accur =  1.0 test_accur =  0.8358183079056866\n",
      "Epoch :  858 training_loss =  0.03322888067512487 test_loss =  0.46533844766985183 train_accur =  1.0 test_accur =  0.8357605177993528\n",
      "Epoch :  859 training_loss =  0.033173630287173864 test_loss =  0.46533942044811344 train_accur =  1.0 test_accur =  0.8357605177993528\n",
      "Epoch :  860 training_loss =  0.033118522101019426 test_loss =  0.4653430811628932 train_accur =  1.0 test_accur =  0.8357894128525196\n",
      "Epoch :  861 training_loss =  0.03306353329842368 test_loss =  0.4653461220100832 train_accur =  1.0 test_accur =  0.8358905455386038\n",
      "Epoch :  862 training_loss =  0.033008655005831486 test_loss =  0.4653489077378015 train_accur =  1.0 test_accur =  0.8358760980120203\n",
      "Epoch :  863 training_loss =  0.032953903022770466 test_loss =  0.46535249524186867 train_accur =  1.0 test_accur =  0.8358472029588534\n",
      "Epoch :  864 training_loss =  0.03289933317086161 test_loss =  0.46535578597486116 train_accur =  1.0 test_accur =  0.8358760980120203\n",
      "Epoch :  865 training_loss =  0.03284513770112776 test_loss =  0.4653469600586989 train_accur =  1.0 test_accur =  0.8359916782246879\n",
      "Epoch :  866 training_loss =  0.032790909446361344 test_loss =  0.4653608431744004 train_accur =  1.0 test_accur =  0.8360639158576052\n",
      "Epoch :  867 training_loss =  0.03273681474929087 test_loss =  0.4653874309146164 train_accur =  1.0 test_accur =  0.8360783633841886\n",
      "Epoch :  868 training_loss =  0.032681213290864985 test_loss =  0.46540436290677545 train_accur =  1.0 test_accur =  0.836092810910772\n",
      "Epoch :  869 training_loss =  0.03262407386791495 test_loss =  0.4654051773261526 train_accur =  1.0 test_accur =  0.836092810910772\n",
      "Epoch :  870 training_loss =  0.03256668719366174 test_loss =  0.4653982931429885 train_accur =  1.0 test_accur =  0.8360783633841886\n",
      "Epoch :  871 training_loss =  0.032510085606310676 test_loss =  0.46539027416825934 train_accur =  1.0 test_accur =  0.8360783633841886\n",
      "Epoch :  872 training_loss =  0.03245470765599762 test_loss =  0.46538180079142927 train_accur =  1.0 test_accur =  0.8361072584373556\n",
      "Epoch :  873 training_loss =  0.03240039615712864 test_loss =  0.4653746314911147 train_accur =  1.0 test_accur =  0.836092810910772\n",
      "Epoch :  874 training_loss =  0.03234694579419345 test_loss =  0.4653714983174863 train_accur =  1.0 test_accur =  0.836092810910772\n",
      "Epoch :  875 training_loss =  0.0322944154678485 test_loss =  0.46537316450844235 train_accur =  1.0 test_accur =  0.8361072584373556\n",
      "Epoch :  876 training_loss =  0.032242904793997426 test_loss =  0.46536383805095477 train_accur =  1.0 test_accur =  0.8361072584373556\n",
      "Epoch :  877 training_loss =  0.03219185881517868 test_loss =  0.4653533431532753 train_accur =  1.0 test_accur =  0.8361072584373556\n",
      "Epoch :  878 training_loss =  0.03214112054668311 test_loss =  0.46534358697386724 train_accur =  1.0 test_accur =  0.8361361534905224\n",
      "Epoch :  879 training_loss =  0.03209050253387827 test_loss =  0.4653347385131161 train_accur =  1.0 test_accur =  0.8361794960702728\n",
      "Epoch :  880 training_loss =  0.03204004196825302 test_loss =  0.4653268373520385 train_accur =  1.0 test_accur =  0.8362372861766065\n",
      "Epoch :  881 training_loss =  0.03198976687118783 test_loss =  0.46531971621574464 train_accur =  1.0 test_accur =  0.8362228386500231\n",
      "Epoch :  882 training_loss =  0.03193967530459217 test_loss =  0.4653132800471782 train_accur =  1.0 test_accur =  0.8362372861766065\n",
      "Epoch :  883 training_loss =  0.031889740935390175 test_loss =  0.46530868145250254 train_accur =  1.0 test_accur =  0.8362950762829403\n",
      "Epoch :  884 training_loss =  0.03183988348178087 test_loss =  0.4653070481331228 train_accur =  1.0 test_accur =  0.8363673139158576\n",
      "Epoch :  885 training_loss =  0.031790057561561544 test_loss =  0.46529815024860394 train_accur =  1.0 test_accur =  0.8364395515487748\n",
      "Epoch :  886 training_loss =  0.031740304974144054 test_loss =  0.4652837358422296 train_accur =  1.0 test_accur =  0.8364539990753583\n",
      "Epoch :  887 training_loss =  0.0316905364171411 test_loss =  0.4652693984854857 train_accur =  1.0 test_accur =  0.8364684466019418\n",
      "Epoch :  888 training_loss =  0.03164072944759928 test_loss =  0.4652562737282777 train_accur =  1.0 test_accur =  0.8364828941285252\n",
      "Epoch :  889 training_loss =  0.03159089044126702 test_loss =  0.465244858293004 train_accur =  1.0 test_accur =  0.8365406842348589\n",
      "Epoch :  890 training_loss =  0.031541050218127344 test_loss =  0.4652354451512102 train_accur =  1.0 test_accur =  0.8365406842348589\n",
      "Epoch :  891 training_loss =  0.03149126616910239 test_loss =  0.4652269402706944 train_accur =  1.0 test_accur =  0.8365984743411928\n",
      "Epoch :  892 training_loss =  0.03144158967029724 test_loss =  0.46521875817632374 train_accur =  1.0 test_accur =  0.8366562644475266\n",
      "Epoch :  893 training_loss =  0.03139214922543615 test_loss =  0.4652108226940475 train_accur =  1.0 test_accur =  0.8366562644475266\n",
      "Epoch :  894 training_loss =  0.03134354436846124 test_loss =  0.4652038014276473 train_accur =  1.0 test_accur =  0.83667071197411\n",
      "Epoch :  895 training_loss =  0.03129584877988012 test_loss =  0.4651939742375915 train_accur =  1.0 test_accur =  0.8366418169209431\n",
      "Epoch :  896 training_loss =  0.03124764944297083 test_loss =  0.4651890916483324 train_accur =  1.0 test_accur =  0.8367285020804438\n",
      "Epoch :  897 training_loss =  0.03119593560324481 test_loss =  0.46519895097722075 train_accur =  1.0 test_accur =  0.8367573971336107\n",
      "Epoch :  898 training_loss =  0.03114570747343426 test_loss =  0.4652064644967626 train_accur =  1.0 test_accur =  0.8368007397133611\n",
      "Epoch :  899 training_loss =  0.03109559350250972 test_loss =  0.4652139067057139 train_accur =  1.0 test_accur =  0.8367718446601942\n",
      "Epoch :  900 training_loss =  0.031045018789672897 test_loss =  0.465223814013339 train_accur =  1.0 test_accur =  0.8368151872399445\n",
      "Epoch :  901 training_loss =  0.030993944985921115 test_loss =  0.4652377102292428 train_accur =  1.0 test_accur =  0.8367573971336107\n",
      "Epoch :  902 training_loss =  0.03094315851026211 test_loss =  0.46525316971925557 train_accur =  1.0 test_accur =  0.8367285020804438\n",
      "Epoch :  903 training_loss =  0.030892968097673116 test_loss =  0.4652650751605476 train_accur =  1.0 test_accur =  0.8367862921867776\n",
      "Epoch :  904 training_loss =  0.03084407214698274 test_loss =  0.46525940468611265 train_accur =  1.0 test_accur =  0.8369018723994452\n",
      "Epoch :  905 training_loss =  0.030795585035371824 test_loss =  0.4652517631162703 train_accur =  1.0 test_accur =  0.8369452149791956\n",
      "Epoch :  906 training_loss =  0.03074727909726856 test_loss =  0.4652460505713995 train_accur =  1.0 test_accur =  0.8370174526121128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  907 training_loss =  0.030699201266934668 test_loss =  0.46524178362656277 train_accur =  1.0 test_accur =  0.8370896902450301\n",
      "Epoch :  908 training_loss =  0.03065133133184902 test_loss =  0.4652393472357153 train_accur =  1.0 test_accur =  0.8371763754045307\n",
      "Epoch :  909 training_loss =  0.030603652757323095 test_loss =  0.4652385711237516 train_accur =  1.0 test_accur =  0.8373497457235322\n",
      "Epoch :  910 training_loss =  0.03055621289685974 test_loss =  0.46523889641860017 train_accur =  1.0 test_accur =  0.8374075358298659\n",
      "Epoch :  911 training_loss =  0.03050894226204743 test_loss =  0.4652354894817512 train_accur =  1.0 test_accur =  0.8374219833564494\n",
      "Epoch :  912 training_loss =  0.030461705214812642 test_loss =  0.46522879047543847 train_accur =  1.0 test_accur =  0.8374797734627831\n",
      "Epoch :  913 training_loss =  0.030414496101642242 test_loss =  0.4652257733386834 train_accur =  1.0 test_accur =  0.8375231160425335\n",
      "Epoch :  914 training_loss =  0.030367153131997615 test_loss =  0.4652229552490806 train_accur =  1.0 test_accur =  0.837537563569117\n",
      "Epoch :  915 training_loss =  0.030319200407481352 test_loss =  0.4652171002145764 train_accur =  1.0 test_accur =  0.8375231160425335\n",
      "Epoch :  916 training_loss =  0.03027009867322042 test_loss =  0.4652082297457126 train_accur =  1.0 test_accur =  0.8375520110957004\n",
      "Epoch :  917 training_loss =  0.030221624746407143 test_loss =  0.4652030472516337 train_accur =  1.0 test_accur =  0.8375664586222838\n",
      "Epoch :  918 training_loss =  0.030173721029131982 test_loss =  0.46519959444526304 train_accur =  1.0 test_accur =  0.8375520110957004\n",
      "Epoch :  919 training_loss =  0.03012600300899378 test_loss =  0.4651962155775179 train_accur =  1.0 test_accur =  0.8375953536754508\n",
      "Epoch :  920 training_loss =  0.030078303166288928 test_loss =  0.4651920832849987 train_accur =  1.0 test_accur =  0.8376242487286176\n",
      "Epoch :  921 training_loss =  0.030030493056785214 test_loss =  0.46518647830251725 train_accur =  1.0 test_accur =  0.8376242487286176\n",
      "Epoch :  922 training_loss =  0.02998244332010499 test_loss =  0.4651791546448585 train_accur =  1.0 test_accur =  0.8376242487286176\n",
      "Epoch :  923 training_loss =  0.029933790465754173 test_loss =  0.465169574284496 train_accur =  1.0 test_accur =  0.8376098012020342\n",
      "Epoch :  924 training_loss =  0.029883554199711743 test_loss =  0.4651547592645277 train_accur =  1.0 test_accur =  0.8375953536754508\n",
      "Epoch :  925 training_loss =  0.029828902793439457 test_loss =  0.4651328818464943 train_accur =  1.0 test_accur =  0.8375520110957004\n",
      "Epoch :  926 training_loss =  0.02976025608887797 test_loss =  0.46512692659087534 train_accur =  1.0 test_accur =  0.8375664586222838\n",
      "Epoch :  927 training_loss =  0.02964207746226758 test_loss =  0.46511517932054924 train_accur =  1.0 test_accur =  0.837537563569117\n",
      "Epoch :  928 training_loss =  0.029511227894488287 test_loss =  0.46510372937922206 train_accur =  1.0 test_accur =  0.837537563569117\n",
      "Epoch :  929 training_loss =  0.029459405667398495 test_loss =  0.4650912154675356 train_accur =  1.0 test_accur =  0.8375086685159501\n",
      "Epoch :  930 training_loss =  0.029411956113468175 test_loss =  0.4650869207144198 train_accur =  1.0 test_accur =  0.8374653259361997\n",
      "Epoch :  931 training_loss =  0.029366497989129485 test_loss =  0.46508650412769653 train_accur =  1.0 test_accur =  0.8374075358298659\n",
      "Epoch :  932 training_loss =  0.029322214963793433 test_loss =  0.465089259593192 train_accur =  1.0 test_accur =  0.8374364308830329\n",
      "Epoch :  933 training_loss =  0.029278542874819125 test_loss =  0.46509460469500163 train_accur =  1.0 test_accur =  0.8374508784096163\n",
      "Epoch :  934 training_loss =  0.029235082576120147 test_loss =  0.46509860217923354 train_accur =  1.0 test_accur =  0.8374797734627831\n",
      "Epoch :  935 training_loss =  0.02919166385118723 test_loss =  0.4650995659053889 train_accur =  1.0 test_accur =  0.8374942209893667\n",
      "Epoch :  936 training_loss =  0.029148244079597763 test_loss =  0.4651004242065313 train_accur =  1.0 test_accur =  0.8374942209893667\n",
      "Epoch :  937 training_loss =  0.02910472127475766 test_loss =  0.46510233789275984 train_accur =  1.0 test_accur =  0.8374797734627831\n",
      "Epoch :  938 training_loss =  0.02906092861182341 test_loss =  0.46510631451252565 train_accur =  1.0 test_accur =  0.8374075358298659\n",
      "Epoch :  939 training_loss =  0.029016580277316153 test_loss =  0.4651143695612695 train_accur =  1.0 test_accur =  0.8372341655108645\n",
      "Epoch :  940 training_loss =  0.02897117034875322 test_loss =  0.46513094851145526 train_accur =  1.0 test_accur =  0.8371041377716135\n",
      "Epoch :  941 training_loss =  0.028923739872707927 test_loss =  0.46514719303275803 train_accur =  1.0 test_accur =  0.8370896902450301\n",
      "Epoch :  942 training_loss =  0.028873113128180784 test_loss =  0.4651421588801116 train_accur =  1.0 test_accur =  0.8370030050855294\n",
      "Epoch :  943 training_loss =  0.02882085922092654 test_loss =  0.46513757635648306 train_accur =  1.0 test_accur =  0.8370030050855294\n",
      "Epoch :  944 training_loss =  0.028770919675273232 test_loss =  0.4651361347445679 train_accur =  1.0 test_accur =  0.8369307674526121\n",
      "Epoch :  945 training_loss =  0.02872447384242373 test_loss =  0.46514117211110745 train_accur =  1.0 test_accur =  0.8369163199260287\n",
      "Epoch :  946 training_loss =  0.028679071430605677 test_loss =  0.4651492054311057 train_accur =  1.0 test_accur =  0.8368585298196949\n",
      "Epoch :  947 training_loss =  0.02863355330104924 test_loss =  0.46515277371847363 train_accur =  1.0 test_accur =  0.8369307674526121\n",
      "Epoch :  948 training_loss =  0.02858879698656749 test_loss =  0.46514279242572537 train_accur =  1.0 test_accur =  0.8369307674526121\n",
      "Epoch :  949 training_loss =  0.02854555533163332 test_loss =  0.4651401959102489 train_accur =  1.0 test_accur =  0.8370030050855294\n",
      "Epoch :  950 training_loss =  0.028502431057617628 test_loss =  0.4651393960264044 train_accur =  1.0 test_accur =  0.8369018723994452\n",
      "Epoch :  951 training_loss =  0.02845900600876243 test_loss =  0.4651391119050616 train_accur =  1.0 test_accur =  0.8368874248728617\n",
      "Epoch :  952 training_loss =  0.02841561094711862 test_loss =  0.46513881346950886 train_accur =  1.0 test_accur =  0.8368585298196949\n",
      "Epoch :  953 training_loss =  0.02837235862271116 test_loss =  0.46513840058600436 train_accur =  1.0 test_accur =  0.8368151872399445\n",
      "Epoch :  954 training_loss =  0.028329268877608248 test_loss =  0.46513871172740007 train_accur =  1.0 test_accur =  0.8367718446601942\n",
      "Epoch :  955 training_loss =  0.028286330167457834 test_loss =  0.4651387416896917 train_accur =  1.0 test_accur =  0.8367718446601942\n",
      "Epoch :  956 training_loss =  0.028243501945296394 test_loss =  0.46513759608865424 train_accur =  1.0 test_accur =  0.8367285020804438\n",
      "Epoch :  957 training_loss =  0.028200751589916827 test_loss =  0.4651352784637313 train_accur =  1.0 test_accur =  0.836699607027277\n",
      "Epoch :  958 training_loss =  0.02815805060740409 test_loss =  0.4651321545217572 train_accur =  1.0 test_accur =  0.8366851595006934\n",
      "Epoch :  959 training_loss =  0.028115361134257316 test_loss =  0.465128628068606 train_accur =  1.0 test_accur =  0.8366851595006934\n",
      "Epoch :  960 training_loss =  0.02807263640631278 test_loss =  0.465125073231162 train_accur =  1.0 test_accur =  0.83667071197411\n",
      "Epoch :  961 training_loss =  0.028029836589738268 test_loss =  0.4651218800532702 train_accur =  1.0 test_accur =  0.8366418169209431\n",
      "Epoch :  962 training_loss =  0.027986958174303307 test_loss =  0.4651194940862312 train_accur =  1.0 test_accur =  0.8366418169209431\n",
      "Epoch :  963 training_loss =  0.027944064290466225 test_loss =  0.4651183424075565 train_accur =  1.0 test_accur =  0.8366273693943597\n",
      "Epoch :  964 training_loss =  0.027901281394979882 test_loss =  0.46511846040032523 train_accur =  1.0 test_accur =  0.8366273693943597\n",
      "Epoch :  965 training_loss =  0.027858746718211685 test_loss =  0.4651189255924335 train_accur =  1.0 test_accur =  0.8366562644475266\n",
      "Epoch :  966 training_loss =  0.02781656814791511 test_loss =  0.46511836822647196 train_accur =  1.0 test_accur =  0.8366562644475266\n",
      "Epoch :  967 training_loss =  0.027774863071568616 test_loss =  0.4651158227004346 train_accur =  1.0 test_accur =  0.8366418169209431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  968 training_loss =  0.02773389480932189 test_loss =  0.4651112981281309 train_accur =  1.0 test_accur =  0.8366418169209431\n",
      "Epoch :  969 training_loss =  0.027693860381987574 test_loss =  0.46510820613212894 train_accur =  1.0 test_accur =  0.8365840268146093\n",
      "Epoch :  970 training_loss =  0.027654254921425134 test_loss =  0.4651110668822527 train_accur =  1.0 test_accur =  0.8365840268146093\n",
      "Epoch :  971 training_loss =  0.027614805402806752 test_loss =  0.46511894738318316 train_accur =  1.0 test_accur =  0.8365984743411928\n",
      "Epoch :  972 training_loss =  0.02757544492408557 test_loss =  0.46513020827324664 train_accur =  1.0 test_accur =  0.8365984743411928\n",
      "Epoch :  973 training_loss =  0.027536213091911333 test_loss =  0.4651450754705373 train_accur =  1.0 test_accur =  0.8365840268146093\n",
      "Epoch :  974 training_loss =  0.027497121811368548 test_loss =  0.46516732639060937 train_accur =  1.0 test_accur =  0.8365695792880259\n",
      "Epoch :  975 training_loss =  0.027458244324092176 test_loss =  0.4652072315396797 train_accur =  1.0 test_accur =  0.8366273693943597\n",
      "Epoch :  976 training_loss =  0.02741967215807581 test_loss =  0.46524966018575914 train_accur =  1.0 test_accur =  0.83667071197411\n",
      "Epoch :  977 training_loss =  0.02738065551330878 test_loss =  0.4652428968245417 train_accur =  1.0 test_accur =  0.8366562644475266\n",
      "Epoch :  978 training_loss =  0.02734170467463715 test_loss =  0.46524436189933266 train_accur =  1.0 test_accur =  0.8367573971336107\n",
      "Epoch :  979 training_loss =  0.027302694413106662 test_loss =  0.46524550633214595 train_accur =  1.0 test_accur =  0.8367573971336107\n",
      "Epoch :  980 training_loss =  0.027263535519192184 test_loss =  0.4652440327644924 train_accur =  1.0 test_accur =  0.8367718446601942\n",
      "Epoch :  981 training_loss =  0.02722418631988978 test_loss =  0.46524012053657465 train_accur =  1.0 test_accur =  0.8368007397133611\n",
      "Epoch :  982 training_loss =  0.027184603421172945 test_loss =  0.46523442705038326 train_accur =  1.0 test_accur =  0.8368440822931115\n",
      "Epoch :  983 training_loss =  0.02714468046658427 test_loss =  0.46522733450631776 train_accur =  1.0 test_accur =  0.8368151872399445\n",
      "Epoch :  984 training_loss =  0.02710425806111104 test_loss =  0.46522059306682995 train_accur =  1.0 test_accur =  0.8368296347665279\n",
      "Epoch :  985 training_loss =  0.02706327133366896 test_loss =  0.4652205394748276 train_accur =  1.0 test_accur =  0.8368296347665279\n",
      "Epoch :  986 training_loss =  0.02702016094702446 test_loss =  0.4652140195390941 train_accur =  1.0 test_accur =  0.8368729773462783\n",
      "Epoch :  987 training_loss =  0.02697643769485605 test_loss =  0.46521129906728703 train_accur =  1.0 test_accur =  0.8369307674526121\n",
      "Epoch :  988 training_loss =  0.026933953900744958 test_loss =  0.46521317276959373 train_accur =  1.0 test_accur =  0.8370030050855294\n",
      "Epoch :  989 training_loss =  0.026893303362013864 test_loss =  0.46521896284701597 train_accur =  1.0 test_accur =  0.8371330328247804\n",
      "Epoch :  990 training_loss =  0.0268538430599609 test_loss =  0.4652284743974 train_accur =  1.0 test_accur =  0.8371474803513639\n",
      "Epoch :  991 training_loss =  0.0268150486990332 test_loss =  0.4652420804019998 train_accur =  1.0 test_accur =  0.8371908229311142\n",
      "Epoch :  992 training_loss =  0.026776676211763502 test_loss =  0.4652592422447121 train_accur =  1.0 test_accur =  0.8373641932501156\n",
      "Epoch :  993 training_loss =  0.026738603283349233 test_loss =  0.4652757019204742 train_accur =  1.0 test_accur =  0.8374219833564494\n",
      "Epoch :  994 training_loss =  0.026700732212844774 test_loss =  0.46528547950235716 train_accur =  1.0 test_accur =  0.8375231160425335\n",
      "Epoch :  995 training_loss =  0.026662956678403533 test_loss =  0.46528924196910126 train_accur =  1.0 test_accur =  0.8374942209893667\n",
      "Epoch :  996 training_loss =  0.02662516846034218 test_loss =  0.4652914694393135 train_accur =  1.0 test_accur =  0.8375520110957004\n",
      "Epoch :  997 training_loss =  0.026587337572409248 test_loss =  0.4652934303652129 train_accur =  1.0 test_accur =  0.8375664586222838\n",
      "Epoch :  998 training_loss =  0.026549493350355828 test_loss =  0.46529498042647827 train_accur =  1.0 test_accur =  0.8376098012020342\n",
      "Epoch :  999 training_loss =  0.026511661382566235 test_loss =  0.4652962831486667 train_accur =  1.0 test_accur =  0.8376386962552012\n",
      "Epoch :  1000 training_loss =  0.026473848145831952 test_loss =  0.4652974081232489 train_accur =  1.0 test_accur =  0.837667591308368\n"
     ]
    }
   ],
   "source": [
    "SGD_train_epoch(X_train, Y_train, batch_size = 64, epoch = 1000, learning_rate = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {\"W1\": np.random.randn(400, 784) * np.sqrt(1. / 784),\n",
    "#               \"b1\": np.zeros((400, 1)) * np.sqrt(1. / 784),\n",
    "#               \"W2\": np.random.randn(400, 400) * np.sqrt(1. / 400),\n",
    "#               \"b2\": np.zeros((400, 1)) * np.sqrt(1. / 400),\n",
    "#               \"W3\": np.random.randn(digits, 400) * np.sqrt(1. / 400),\n",
    "#               \"b3\": np.zeros((digits, 1)) * np.sqrt(1. / 400)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward(X, parameters):\n",
    "#     inoutput = {}\n",
    "#     inoutput[\"hiddenlayer1_output_temp\"] = np.matmul(parameters[\"W1\"], X) + parameters[\"b1\"]\n",
    "#     inoutput[\"hiddenlayer1_output\"] = sigmoid(inoutput[\"hiddenlayer1_output_temp\"])\n",
    "    \n",
    "#     inoutput[\"hiddenlayer2_output_temp\"] = np.matmul(parameters[\"W2\"], inoutput[\"hiddenlayer1_output\"]) + parameters[\"b2\"]\n",
    "#     inoutput[\"hiddenlayer2_output\"] = sigmoid(inoutput[\"hiddenlayer2_output_temp\"])\n",
    "    \n",
    "#     inoutput[\"outputlayer_output_temp\"] = np.matmul(parameters[\"W3\"], inoutput[\"hiddenlayer2_output\"]) + parameters[\"b3\"]\n",
    "#     inoutput[\"outputlayer_output\"] = softmax(inoutput[\"outputlayer_output_temp\"])\n",
    "#     #inoutput[\"outputlayer_output\"] = y_hat\n",
    "\n",
    "#     return inoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def back_propagation(X, Y, parameters, inoutput, m_batch):\n",
    "#     CE_gradient = inoutput[\"outputlayer_output\"] - Y\n",
    "\n",
    "#     W3_gradient = (1. / m_batch) * np.matmul(CE_gradient, inoutput[\"hiddenlayer2_output\"].T)\n",
    "#     b3_gradient = (1. / m_batch) * np.sum(CE_gradient, axis=1, keepdims=True)\n",
    "\n",
    "#     # ---\n",
    "\n",
    "#     outputlayer_backward_output = np.matmul(parameters[\"W3\"].T, CE_gradient)\n",
    "#     hiddenlayer2_backward_input = outputlayer_backward_output * sigmoid_gradient(inoutput[\"hiddenlayer2_output_temp\"])\n",
    "\n",
    "#     W2_gradient = (1. / m_batch) * np.matmul(hiddenlayer2_backward_input, inoutput[\"hiddenlayer1_output\"].T)\n",
    "#     b2_gradient = (1. / m_batch) * np.sum(hiddenlayer2_backward_input, axis=1, keepdims=True)\n",
    "\n",
    "#     # ---\n",
    "\n",
    "#     hiddenlayer2_backward_output = np.matmul(parameters[\"W2\"].T, hiddenlayer2_backward_input)\n",
    "#     hiddenlayer1_backward_input = hiddenlayer2_backward_output * sigmoid_gradient(inoutput[\"hiddenlayer1_output_temp\"])\n",
    "\n",
    "#     W1_gradient = (1. / m_batch) * np.matmul(hiddenlayer1_backward_input, X.T)\n",
    "#     b1_gradient = (1. / m_batch) * np.sum(hiddenlayer1_backward_input, axis=1, keepdims=True)\n",
    "\n",
    "#     Wb_gradients = {\"W1_gradient\": W1_gradient, \"b1_gradient\": b1_gradient, \"W2_gradient\": W2_gradient,\n",
    "#                      \"b2_gradient\": b2_gradient, \"W3_gradient\": W3_gradient, \"b3_gradient\": b3_gradient}\n",
    "\n",
    "#     return Wb_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     epoch = 3\n",
    "#     batch_size = 64\n",
    "#     TrainError = []\n",
    "#     TestError = []\n",
    "#     for i in range(epoch):\n",
    "       \n",
    "#         # shuffle training set\n",
    "# #         permutation = np.random.permutation(X_train.shape[1])\n",
    "# #         X_train_shuffled = X_train[:, permutation]\n",
    "# #         Y_train_shuffled = Y_train[:, permutation]\n",
    "    \n",
    "#         batch_num = len(X_train) // batch_size\n",
    "#         predicts = []\n",
    "#         golds = []\n",
    "#         predicts_test = []\n",
    "#         golds_test = []\n",
    "#         learning_rate = 0.03\n",
    "        \n",
    "        \n",
    "#         for j in range(batch_num):\n",
    "#             begin = j * batch_size\n",
    "#             end = min(begin + batch_size, X_train.shape[1] - 1)\n",
    "#             X = X_train[:, begin:end]\n",
    "#             Y = Y_train[:, begin:end]\n",
    "#             m_batch = end - begin\n",
    "            \n",
    "#             inoutput = forward(X, parameters)\n",
    "#             Wb_gradients = back_propagation(X, Y, parameters, inoutput, m_batch)\n",
    "            \n",
    "#             W1_gradient = Wb_gradients[\"W1_gradient\"]\n",
    "#             b1_gradient = Wb_gradients[\"b1_gradient\"]\n",
    "#             W2_gradient = Wb_gradients[\"W2_gradient\"]\n",
    "#             b2_gradient = Wb_gradients[\"b2_gradient\"]\n",
    "#             W3_gradient = Wb_gradients[\"W3_gradient\"]\n",
    "#             b3_gradient = Wb_gradients[\"b3_gradient\"]\n",
    "            \n",
    "#             parameters[\"W1\"] = parameters[\"W1\"] - learning_rate * W1_gradient\n",
    "#             parameters[\"b1\"] = parameters[\"b1\"] - learning_rate * b1_gradient\n",
    "#             parameters[\"W2\"] = parameters[\"W2\"] - learning_rate * W2_gradient\n",
    "#             parameters[\"b2\"] = parameters[\"b2\"] - learning_rate * b2_gradient\n",
    "#             parameters[\"W3\"] = parameters[\"W3\"] - learning_rate * W3_gradient\n",
    "#             parameters[\"b3\"] = parameters[\"b3\"] - learning_rate * b3_gradient\n",
    "            \n",
    "            \n",
    "          \n",
    "#         inoutput = forward(X_train, parameters)\n",
    "#         #print(Y.shape)\n",
    "        \n",
    "#         #print(inoutput[\"outputlayer_output\"].shape)\n",
    "#         train_loss = cross_entropy(Y_train, inoutput[\"outputlayer_output\"])\n",
    "\n",
    "#         predicts += np.argmax(inoutput[\"outputlayer_output\"], axis=0).tolist()\n",
    "#         golds += np.argmax(Y_train, axis=0).tolist()\n",
    "        \n",
    "#         inoutput = forward(X_test, parameters)\n",
    "#         #print(Y.shape)\n",
    "        \n",
    "#         #print(inoutput[\"outputlayer_output\"].shape)\n",
    "#         test_loss = cross_entropy(Y_test, inoutput[\"outputlayer_output\"])\n",
    "\n",
    "#         predicts_test += np.argmax(inoutput[\"outputlayer_output\"], axis=0).tolist()\n",
    "#         golds_test += np.argmax(Y_test, axis=0).tolist()\n",
    "        \n",
    "#         print(\"Epoch {}: training loss = {},  test loss = {}, Train_accur = {},Test_accur = {}\".format(\n",
    "#             i + 1, train_loss, test_loss, evaluation(predicts, golds), evaluation(predicts_test, golds_test)))\n",
    "\n",
    "#         TrainError.append(1 - evaluation(predicts, golds))\n",
    "#         TestError.append(1 - evaluation(predicts_test, golds_test))\n",
    "        \n",
    "        \n",
    "# #         new_x_axis = np.arange(0,500, 5)\n",
    "# #         fig, ax = plt.subplots(1, 1)\n",
    "# #         print(TrainError.shape)\n",
    "# #         print(new_x_axis.shape)\n",
    "# #         ax.plot(new_x_axis, TrainError)\n",
    "              \n",
    "        \n",
    "# #     with open(\"Train_error_rate.json\", mode=\"w\") as stream:\n",
    "# #         json.dump(TrainError, stream)\n",
    "\n",
    "# #     with open(\"Test_error_rate.json\", mode=\"w\") as stream:\n",
    "# #         json.dump(TestError, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
